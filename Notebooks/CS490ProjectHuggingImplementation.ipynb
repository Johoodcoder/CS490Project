{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS490Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsmv+e9pKBkL67Sg4vmKjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johoodcoder/CS490Project/blob/hood/Notebooks/CS490ProjectHuggingImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTZbJ1SJ53XO"
      },
      "source": [
        "Non-preinstalled module installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm5_ujD458U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd94e02-c313-4d8b-ba44-c2c46c5b1fe1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWz664Rd6MeU"
      },
      "source": [
        "Import all the stuff we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbufH4ZX8X5N"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CONST_BATCH_SIZE = 10\n",
        "CONST_MAX_SEQ_LENGTH = 128\n",
        "CONST_NUM_EPOCHS = 4\n",
        "CONST_LEARN_RATE = 2e-5\n",
        "CONST_EPSILON = 1e-8"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2AUQtRf6SiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b690c8f-8a66-4980-fc39-3990c1818ce4"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9SFswG6GWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d72e3e-2d50-470a-d672-2c5e3a11bd14"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUA3aAGM7G7u"
      },
      "source": [
        "Load our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a-5pyC08dzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d362f3d8-c631-40b6-ed36-54c19351c8ae"
      },
      "source": [
        "# Load dataset\n",
        "# df = pd.read_csv(\"condensed_fake_real_news_SANITIZED.csv\")\n",
        "df = pd.read_csv(\"LIARPLUSTrainSanitized.csv\")\n",
        "df = df[['text', 'type']]\n",
        "print('Total number of data entries: {:,}\\n'.format(df.shape[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of data entries: 10,234\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHnQVRq8z0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2a34899b-ff0e-4617-cdd5-3d41062301ea"
      },
      "source": [
        "df = df[df['type'].isin(['fake', 'real'])]\n",
        "# Scramble data indexes from dataset. Random_state is a seed. This is producing random scrambles for some reason even with the same random_state seed.\n",
        "df = df.dropna()\n",
        "df = df.sample(frac=1, random_state = 23).reset_index(drop=True)\n",
        "df.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6554</th>\n",
              "      <td>She and other experts emphasize that a person'...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3615</th>\n",
              "      <td>So, for all the sacrifices that you've made, I...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>Silverman forwarded a social media meme that s...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9767</th>\n",
              "      <td>This is quite a leap in logic. But thats quest...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8795</th>\n",
              "      <td>Christie said: \"We are coming up on our 40th a...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7330</th>\n",
              "      <td>And even if it did, it may not ever be possibl...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>The rate does not include people who have drop...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5987</th>\n",
              "      <td>ECONorthwest, in preparing a paper delineating...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1580</th>\n",
              "      <td>However, it looks like there was another messa...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5511</th>\n",
              "      <td>Santorum said, \"The most recent survey of clim...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  type\n",
              "6554  She and other experts emphasize that a person'...  real\n",
              "3615  So, for all the sacrifices that you've made, I...  fake\n",
              "578   Silverman forwarded a social media meme that s...  real\n",
              "9767  This is quite a leap in logic. But thats quest...  fake\n",
              "8795  Christie said: \"We are coming up on our 40th a...  real\n",
              "7330  And even if it did, it may not ever be possibl...  fake\n",
              "4748  The rate does not include people who have drop...  real\n",
              "5987  ECONorthwest, in preparing a paper delineating...  real\n",
              "1580  However, it looks like there was another messa...  real\n",
              "5511  Santorum said, \"The most recent survey of clim...  fake"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSluqzG8-lh"
      },
      "source": [
        "Seperate training and testing subsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wOwpOde8_WC"
      },
      "source": [
        "train_data_df = df.head(1000)\n",
        "test_data_df = df.tail(200)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_VsapAk87Kk"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "train_texts = train_data_df.text.values\n",
        "train_labels = train_data_df.type.values\n",
        "\n",
        "test_texts = test_data_df.text.values\n",
        "test_labels = test_data_df.type.values\n",
        "\n",
        "# If value == fake then make it 1. Else 0. Funky workaround as bert expects longs\n",
        "train_labels = np.array(train_labels == 'fake')\n",
        "train_labels = np.multiply(train_labels,1)\n",
        "test_labels = np.array(test_labels) == 'fake'\n",
        "test_labels = np.multiply(test_labels,1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86XhtxYQ94QM"
      },
      "source": [
        "Load and test tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQi8q3Fs9tqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bd1d84-24bb-4c0b-b32d-20991f611249"
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', train_texts[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(train_texts[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_texts[0])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            " Original:  Bike Austin said: \"Bike lanes and sidewalks have been proven to reduce crashes by up to 38 percent on Austins streets. \"Research suggests big drops in pedestrian-vehicle accidents when sidewalks are introduced. But Bike Austin didnt offer nor did we find research showing the addition of bike lanes in themselves or bike lanes plus sidewalks resulted in anypercentage plummet in crashes. Instead, the city analysisstates that reconfiguring lanes on part of one road, which also gainedbike lanes, preceded 38 percent fewercrashes--with crashreductions averaging 29 percent among five road-diet projects.\n",
            "Tokenized:  ['bike', 'austin', 'said', ':', '\"', 'bike', 'lanes', 'and', 'sidewalks', 'have', 'been', 'proven', 'to', 'reduce', 'crashes', 'by', 'up', 'to', '38', 'percent', 'on', 'austin', '##s', 'streets', '.', '\"', 'research', 'suggests', 'big', 'drops', 'in', 'pedestrian', '-', 'vehicle', 'accidents', 'when', 'sidewalks', 'are', 'introduced', '.', 'but', 'bike', 'austin', 'didn', '##t', 'offer', 'nor', 'did', 'we', 'find', 'research', 'showing', 'the', 'addition', 'of', 'bike', 'lanes', 'in', 'themselves', 'or', 'bike', 'lanes', 'plus', 'sidewalks', 'resulted', 'in', 'any', '##per', '##cent', '##age', 'plum', '##met', 'in', 'crashes', '.', 'instead', ',', 'the', 'city', 'analysis', '##sta', '##tes', 'that', 'rec', '##on', '##fi', '##gur', '##ing', 'lanes', 'on', 'part', 'of', 'one', 'road', ',', 'which', 'also', 'gained', '##bi', '##ke', 'lanes', ',', 'preceded', '38', 'percent', 'fewer', '##cr', '##ash', '##es', '-', '-', 'with', 'crash', '##red', '##uc', '##tions', 'averaging', '29', 'percent', 'among', 'five', 'road', '-', 'diet', 'projects', '.']\n",
            "Token IDs:  [7997, 5899, 2056, 1024, 1000, 7997, 10914, 1998, 28386, 2031, 2042, 10003, 2000, 5547, 19119, 2011, 2039, 2000, 4229, 3867, 2006, 5899, 2015, 4534, 1012, 1000, 2470, 6083, 2502, 9010, 1999, 14662, 1011, 4316, 13436, 2043, 28386, 2024, 3107, 1012, 2021, 7997, 5899, 2134, 2102, 3749, 4496, 2106, 2057, 2424, 2470, 4760, 1996, 2804, 1997, 7997, 10914, 1999, 3209, 2030, 7997, 10914, 4606, 28386, 4504, 1999, 2151, 4842, 13013, 4270, 22088, 11368, 1999, 19119, 1012, 2612, 1010, 1996, 2103, 4106, 9153, 4570, 2008, 28667, 2239, 8873, 27390, 2075, 10914, 2006, 2112, 1997, 2028, 2346, 1010, 2029, 2036, 4227, 5638, 3489, 10914, 1010, 11677, 4229, 3867, 8491, 26775, 11823, 2229, 1011, 1011, 2007, 5823, 5596, 14194, 9285, 14985, 2756, 3867, 2426, 2274, 2346, 1011, 8738, 3934, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIuVMsx-NJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487de2ad-41e1-49d0-ffca-d6a663926593"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every news text...\n",
        "for text in train_texts:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum text length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max text length: ', max_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max text length:  310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPRn2Sta-k1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe98794-d9e8-4668-b588-2b97ee502f2e"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training entries: {:,}\\n'.format(train_data_df.shape[0]))\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for text in train_texts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = CONST_MAX_SEQ_LENGTH,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train_labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of training entries: 1,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Bike Austin said: \"Bike lanes and sidewalks have been proven to reduce crashes by up to 38 percent on Austins streets. \"Research suggests big drops in pedestrian-vehicle accidents when sidewalks are introduced. But Bike Austin didnt offer nor did we find research showing the addition of bike lanes in themselves or bike lanes plus sidewalks resulted in anypercentage plummet in crashes. Instead, the city analysisstates that reconfiguring lanes on part of one road, which also gainedbike lanes, preceded 38 percent fewercrashes--with crashreductions averaging 29 percent among five road-diet projects.\n",
            "Token IDs: tensor([  101,  7997,  5899,  2056,  1024,  1000,  7997, 10914,  1998, 28386,\n",
            "         2031,  2042, 10003,  2000,  5547, 19119,  2011,  2039,  2000,  4229,\n",
            "         3867,  2006,  5899,  2015,  4534,  1012,  1000,  2470,  6083,  2502,\n",
            "         9010,  1999, 14662,  1011,  4316, 13436,  2043, 28386,  2024,  3107,\n",
            "         1012,  2021,  7997,  5899,  2134,  2102,  3749,  4496,  2106,  2057,\n",
            "         2424,  2470,  4760,  1996,  2804,  1997,  7997, 10914,  1999,  3209,\n",
            "         2030,  7997, 10914,  4606, 28386,  4504,  1999,  2151,  4842, 13013,\n",
            "         4270, 22088, 11368,  1999, 19119,  1012,  2612,  1010,  1996,  2103,\n",
            "         4106,  9153,  4570,  2008, 28667,  2239,  8873, 27390,  2075, 10914,\n",
            "         2006,  2112,  1997,  2028,  2346,  1010,  2029,  2036,  4227,  5638,\n",
            "         3489, 10914,  1010, 11677,  4229,  3867,  8491, 26775, 11823,  2229,\n",
            "         1011,  1011,  2007,  5823,  5596, 14194,  9285, 14985,  2756,  3867,\n",
            "         2426,  2274,  2346,  1011,  8738,  3934,  1012,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbspJd0B_zWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a600a3-8902-4164-9432-a32fae8a9849"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  900 training samples\n",
            "  100 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0x6YgtAFm8"
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = CONST_BATCH_SIZE\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZRYYD-5AOdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe8377f-6178-4d43-acd2-25f608a31d70"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iznqE09hAXat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71edf234-1354-451b-c600-772b9230f23c"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3lXGKtmAckv"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = CONST_LEARN_RATE, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = CONST_EPSILON # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5QfRjwoAkMc"
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = CONST_NUM_EPOCHS\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWtGyTIKAt-B"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58So89vWA7wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48e4744-0bd4-461c-e67b-60152bc6227b"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:08 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "of5AwpaONAph",
        "outputId": "9eb6253b-c6af-4af8-9e98-f7fa7e71f9da"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.44</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.62         0.60           0.70       0:00:45         0:00:02\n",
              "2               0.59         0.64           0.71       0:00:45         0:00:02\n",
              "3               0.52         0.72           0.68       0:00:45         0:00:02\n",
              "4               0.44         0.72           0.66       0:00:45         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drU08e--BJEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "8ff21f8e-6f43-4e50-b2eb-d1b7d4d3a922"
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7fa8c03f7910>,\n",
              "  <matplotlib.axis.XTick at 0x7fa8c03f7110>,\n",
              "  <matplotlib.axis.XTick at 0x7fa8c0637210>,\n",
              "  <matplotlib.axis.XTick at 0x7fa888d79d50>],\n",
              " <a list of 4 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsQGHV-6NTrg",
        "outputId": "fa23a937-273b-44a6-9366-1813ace43584"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of test entries: {:,}\\n'.format(test_data_df.shape[0]))\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for text in test_texts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = CONST_MAX_SEQ_LENGTH,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = CONST_BATCH_SIZE  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test entries: 200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LarLkCN1Qh5E",
        "outputId": "6ca3f6f5-95eb-48f8-83c5-e2d060820adf"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 200 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3El4O9kASTtX",
        "outputId": "0ad95c2c-394a-4f24-b662-5a84f1c2c162"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (test_labels.sum(), len(test_labels), (test_labels.sum() / len(test_labels) * 100.0)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 59 of 200 (29.50%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAtj6RjqThiP",
        "outputId": "d57697c2-0eca-4762-d756-32b8ca36d1b5"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "QP1PY1UFVwIT",
        "outputId": "b8f78218-f99c-4eb0-b11c-0f66dd17f80e"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrXvz8jhWANB",
        "outputId": "9a2d9cc0-efb6-4f7c-96e5-7289f021e740"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: -0.064\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}