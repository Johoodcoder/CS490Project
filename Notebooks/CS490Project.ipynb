{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS490Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johoodcoder/CS490Project/blob/whittington/Notebooks/CS490Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTZbJ1SJ53XO"
      },
      "source": [
        "Non-preinstalled module installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm5_ujD458U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe86e3ce-9805-411d-e838-1720aa68252d"
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/bd/3f9cc87a8faa561903644ec6ef7e7e408ca3640e77c5944124ad6adbaecd/boto3-1.17.39-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.0+cu101)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.39\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/ad/abdc982cb695a20764df007a2d7cb0ac8964c9591fd014006e40334e4a74/botocore-1.20.39-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 10.1MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.39->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.39->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.39 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.39 botocore-1.20.39 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.6\n",
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (4.41.1)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw-rU23d7kyr"
      },
      "source": [
        "Import Dataset used in https://towardsdatascience.com/fake-news-classification-with-bert-afbeee601f41"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PN2iZvR7xuA"
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vvyvLZY3Lnl"
      },
      "source": [
        "The base code from https://github.com/spierre91/medium_code/blob/master/fake_news_classifcation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbufH4ZX8X5N"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import torch.nn as nn\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "import torch\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "import gc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a-5pyC08dzO",
        "outputId": "1ab0c228-d41a-4904-fb14-6148ca68485b"
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "train_data, test_data = imdb_dataset(train=True, test=True)\n",
        "#df = pd.read_csv(\"condensed_fake_real_news_SANITIZED.csv\")\n",
        "df = pd.read_csv(\"fnn_train.csv\")\n",
        "#df = df[['text', 'type']]\n",
        "df = df[['fullText_based_content', 'label_fnn']]\n",
        "print(len(df))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 84.1MB [00:01, 48.2MB/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7MfTPO18kw8",
        "outputId": "ec5f5f50-aecf-46aa-851a-0bffaed12ddc"
      },
      "source": [
        "from collections import Counter \n",
        "\n",
        "#print(Counter(df['type'].values))\n",
        "print(Counter(df['label_fnn'].values))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'fake': 7621, 'real': 7591})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HHnQVRq8z0n",
        "outputId": "4ed539a7-8e24-4ed5-d46b-3852668c02c0"
      },
      "source": [
        "df = df[df['label_fnn'].isin(['fake', 'real'])]\n",
        "#df = df[df['type'].isin(['fake', 'real'])]\n",
        "df.dropna(inplace = True)\n",
        "df = df.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "\n",
        "#print(Counter(df['type'].values))\n",
        "print(Counter(df['label_fnn'].values))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'fake': 7621, 'real': 7591})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wOwpOde8_WC",
        "outputId": "3b48e78a-00f7-418c-a15c-572d182973ed"
      },
      "source": [
        "train_data_df = df.head(3200)\n",
        "test_data_df = df.tail(800)\n",
        "print(train_data_df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 fullText_based_content label_fnn\n",
            "0     The country's economic woes were a somber topi...      real\n",
            "1     The book \"End of Days\" by Sylvia Browne explor...      fake\n",
            "2     Partisan narratives that emerged after the dea...      fake\n",
            "3     The president’s political opponents have \"been...      fake\n",
            "4     In the final days before the election, the Oba...      real\n",
            "...                                                 ...       ...\n",
            "3195  Rumors and news reports citing anonymous sourc...      fake\n",
            "3196  Democratic presidential candidate Hillary Clin...      real\n",
            "3197  Cormick Lynch, a Republican running to replace...      real\n",
            "3198  In a U.S. population of 329 million, is it pos...      fake\n",
            "3199  A political flier directed to voters in north ...      fake\n",
            "\n",
            "[3200 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bborPzYM9CUR"
      },
      "source": [
        "# train_data = []\n",
        "# for index, row in train_data_df.iterrows():\n",
        "#     train_data.append({'text': row['text'], 'type': row['type']})\n",
        "\n",
        "# test_data = []\n",
        "# for index, row in test_data_df.iterrows():\n",
        "#     test_data.append({'text': row['text'], 'type': row['type']})\n",
        "\n",
        "train_data = []\n",
        "for index, row in train_data_df.iterrows():\n",
        "    train_data.append({'fullText_based_content': row['fullText_based_content'], 'label_fnn': row['label_fnn']})\n",
        "\n",
        "test_data = []\n",
        "for index, row in test_data_df.iterrows():\n",
        "    test_data.append({'fullText_based_content': row['fullText_based_content'], 'label_fnn': row['label_fnn']})\n",
        "\n",
        "\n",
        "# train_data = [{'text': text, 'type': type_data } for text in list(train_data['text']) for type_data in list(train_data['type'])]\n",
        "# test_data = [{'text': text, 'type': type_data } for text in list(test_data['text']) for type_data in list(test_data['type'])]\n",
        "# #gc.collect()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G7zoLaF9gNf"
      },
      "source": [
        "# train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['type']), train_data)))\n",
        "# test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))\n",
        "\n",
        "train_texts, train_labels = list(zip(*map(lambda d: (d['fullText_based_content'], d['label_fnn']), train_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['fullText_based_content'], d['label_fnn']), test_data)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KNrngW99ooH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73349862-e9e8-42e6-a730-f248dfce463f"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
        "\n",
        "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
        "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
        "\n",
        "\n",
        "\n",
        "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1201597.98B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAKhviVo9ujZ"
      },
      "source": [
        "train_y = np.array(train_labels) == 'fake'\n",
        "test_y = np.array(test_labels) == 'fake'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWK3NwRHdFbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e572147c-b17a-4727-d787-bab1eecb41b1"
      },
      "source": [
        "print(train_y)\n",
        "print(test_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False  True  True ... False  True  True]\n",
            "[ True False False  True  True False False  True  True  True False False\n",
            "  True False False  True False  True False  True False False  True False\n",
            " False  True  True  True False False False  True False False False False\n",
            "  True  True False False  True False  True  True False False False False\n",
            "  True  True False  True  True  True  True False False False  True  True\n",
            " False  True  True False  True False  True False False False  True False\n",
            "  True  True  True False False  True False  True False False  True False\n",
            "  True False False  True False  True False False False False  True False\n",
            " False False False False  True  True False  True  True False  True False\n",
            "  True  True  True False False False False  True  True False False False\n",
            "  True False False False  True False False False  True  True False  True\n",
            " False  True  True False  True False  True  True False  True  True False\n",
            " False False False  True False False  True False False False False  True\n",
            "  True False  True False  True  True False False  True False  True False\n",
            " False False False  True False  True False False False False False False\n",
            "  True False False  True False  True  True  True False  True False False\n",
            " False  True False  True False  True  True False False  True False  True\n",
            " False  True False  True  True  True False  True False False  True  True\n",
            " False False False  True  True  True False  True  True False False False\n",
            "  True  True False False  True False False  True  True False False False\n",
            "  True  True False False  True  True  True  True  True False  True  True\n",
            " False  True  True  True  True False  True False False False  True False\n",
            "  True False  True False  True False False  True False False False False\n",
            "  True  True False False  True  True False False False False False False\n",
            " False False False  True False False False  True False  True  True  True\n",
            " False False  True  True  True  True  True  True  True  True False  True\n",
            "  True False  True False  True  True  True False  True  True  True  True\n",
            " False False False False False False False False False  True  True False\n",
            "  True False  True  True  True False False  True False False False  True\n",
            "  True False False  True False False False False  True False False False\n",
            "  True  True  True False  True False  True False  True  True  True False\n",
            " False  True False False  True False False False False False  True  True\n",
            "  True  True  True False False False False  True  True  True False  True\n",
            "  True  True  True  True  True  True  True False  True False  True  True\n",
            "  True  True False  True  True  True  True  True False  True  True  True\n",
            " False  True False  True False False False  True  True False  True False\n",
            "  True False  True  True  True  True False False  True False  True  True\n",
            " False False False  True False False False  True  True  True  True False\n",
            " False  True  True False  True  True  True False  True  True  True False\n",
            " False False False False  True False  True  True  True False False  True\n",
            " False  True False False  True False False False False  True False  True\n",
            " False False  True False False  True  True  True False False False  True\n",
            "  True False False  True False False  True  True  True False False False\n",
            "  True False False False False False  True  True  True  True False False\n",
            " False False  True  True  True False False  True False  True False False\n",
            "  True False False False  True False  True False  True  True False  True\n",
            " False False  True False  True  True  True False  True False  True  True\n",
            " False  True  True  True False False  True  True False  True False False\n",
            "  True False  True False False False False False False False False False\n",
            " False False False  True False False False  True  True False False  True\n",
            " False False False  True  True  True  True  True False  True  True False\n",
            " False False False False False False False False  True False  True  True\n",
            " False False  True False  True False  True False  True False  True  True\n",
            "  True False False False  True  True False False  True  True  True False\n",
            " False False  True False False  True False  True  True False  True False\n",
            "  True  True False  True False False False False False False False  True\n",
            " False  True False False False False  True  True  True False  True  True\n",
            " False False  True False False False False False  True  True False  True\n",
            "  True  True False  True False False False False  True  True  True  True\n",
            " False False  True False False False  True  True  True  True False  True\n",
            "  True False  True  True False  True False False  True False  True False\n",
            "  True  True False False False  True  True False  True  True False  True\n",
            " False False  True  True  True False  True False False False  True False\n",
            " False False  True False False False  True False False False  True  True\n",
            " False  True  True  True False False False  True False False  True False\n",
            "  True  True False False False  True  True False False False  True False\n",
            "  True  True  True False False False  True False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKVuGoMm9wXe"
      },
      "source": [
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjP7PqON92FH"
      },
      "source": [
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1poQHOBe-DM6"
      },
      "source": [
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "train_masks_tensor = train_masks_tensor.to('cuda')\n",
        "test_masks_tensor = test_masks_tensor.to('cuda')\n",
        "\n",
        "train_tokens_tensor = train_tokens_tensor.to('cuda')\n",
        "test_tokens_tensor = test_tokens_tensor.to('cuda')\n",
        "train_y_tensor = train_y_tensor.to('cuda')\n",
        "test_y_tensor = test_y_tensor.to('cuda')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VROZ-KLF7oFn"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "EPOCHS = 4"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kHKfGwF-DZp"
      },
      "source": [
        "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
        "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
        "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kdg4sqN-DkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc4553f-67dc-4ed4-fa1d-fe81ddc7e47d"
      },
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf.to('cuda')\n",
        "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-5)\n",
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "        probas = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        batch_loss = loss_func(probas, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:10<00:00, 38742818.96B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "0/400.0 loss: 0.6798498630523682 \n",
            "Epoch:  1\n",
            "1/400.0 loss: 0.712151825428009 \n",
            "Epoch:  1\n",
            "2/400.0 loss: 0.6844405730565389 \n",
            "Epoch:  1\n",
            "3/400.0 loss: 0.7049208283424377 \n",
            "Epoch:  1\n",
            "4/400.0 loss: 0.7287379026412963 \n",
            "Epoch:  1\n",
            "5/400.0 loss: 0.7207578718662262 \n",
            "Epoch:  1\n",
            "6/400.0 loss: 0.7159675444875445 \n",
            "Epoch:  1\n",
            "7/400.0 loss: 0.7181136086583138 \n",
            "Epoch:  1\n",
            "8/400.0 loss: 0.7069890830251906 \n",
            "Epoch:  1\n",
            "9/400.0 loss: 0.7052681267261505 \n",
            "Epoch:  1\n",
            "10/400.0 loss: 0.7063016024502841 \n",
            "Epoch:  1\n",
            "11/400.0 loss: 0.7074139912923177 \n",
            "Epoch:  1\n",
            "12/400.0 loss: 0.7118429037240835 \n",
            "Epoch:  1\n",
            "13/400.0 loss: 0.7086231367928642 \n",
            "Epoch:  1\n",
            "14/400.0 loss: 0.7090950608253479 \n",
            "Epoch:  1\n",
            "15/400.0 loss: 0.7058736868202686 \n",
            "Epoch:  1\n",
            "16/400.0 loss: 0.7036453029688667 \n",
            "Epoch:  1\n",
            "17/400.0 loss: 0.7007512052853903 \n",
            "Epoch:  1\n",
            "18/400.0 loss: 0.6989729404449463 \n",
            "Epoch:  1\n",
            "19/400.0 loss: 0.6994865715503693 \n",
            "Epoch:  1\n",
            "20/400.0 loss: 0.6983175902139573 \n",
            "Epoch:  1\n",
            "21/400.0 loss: 0.6982231465252963 \n",
            "Epoch:  1\n",
            "22/400.0 loss: 0.6993812270786451 \n",
            "Epoch:  1\n",
            "23/400.0 loss: 0.6990740100542704 \n",
            "Epoch:  1\n",
            "24/400.0 loss: 0.7027011084556579 \n",
            "Epoch:  1\n",
            "25/400.0 loss: 0.7021356912759634 \n",
            "Epoch:  1\n",
            "26/400.0 loss: 0.7010415350949323 \n",
            "Epoch:  1\n",
            "27/400.0 loss: 0.7000508095536914 \n",
            "Epoch:  1\n",
            "28/400.0 loss: 0.7007195702914534 \n",
            "Epoch:  1\n",
            "29/400.0 loss: 0.7029358426729838 \n",
            "Epoch:  1\n",
            "30/400.0 loss: 0.7062878128020994 \n",
            "Epoch:  1\n",
            "31/400.0 loss: 0.7014148626476526 \n",
            "Epoch:  1\n",
            "32/400.0 loss: 0.6993044777349993 \n",
            "Epoch:  1\n",
            "33/400.0 loss: 0.6997393492390128 \n",
            "Epoch:  1\n",
            "34/400.0 loss: 0.7001994013786316 \n",
            "Epoch:  1\n",
            "35/400.0 loss: 0.7020849833885828 \n",
            "Epoch:  1\n",
            "36/400.0 loss: 0.6987955328580495 \n",
            "Epoch:  1\n",
            "37/400.0 loss: 0.6982391868766985 \n",
            "Epoch:  1\n",
            "38/400.0 loss: 0.69969915273862 \n",
            "Epoch:  1\n",
            "39/400.0 loss: 0.6988118350505829 \n",
            "Epoch:  1\n",
            "40/400.0 loss: 0.6994544427569319 \n",
            "Epoch:  1\n",
            "41/400.0 loss: 0.6988389094670614 \n",
            "Epoch:  1\n",
            "42/400.0 loss: 0.6981288319410279 \n",
            "Epoch:  1\n",
            "43/400.0 loss: 0.697548886591738 \n",
            "Epoch:  1\n",
            "44/400.0 loss: 0.698728965388404 \n",
            "Epoch:  1\n",
            "45/400.0 loss: 0.6987105154472849 \n",
            "Epoch:  1\n",
            "46/400.0 loss: 0.6981765780043094 \n",
            "Epoch:  1\n",
            "47/400.0 loss: 0.6970660102864107 \n",
            "Epoch:  1\n",
            "48/400.0 loss: 0.696522057056427 \n",
            "Epoch:  1\n",
            "49/400.0 loss: 0.6951289880275726 \n",
            "Epoch:  1\n",
            "50/400.0 loss: 0.6935797672645718 \n",
            "Epoch:  1\n",
            "51/400.0 loss: 0.6924100965261459 \n",
            "Epoch:  1\n",
            "52/400.0 loss: 0.6916683215015339 \n",
            "Epoch:  1\n",
            "53/400.0 loss: 0.6913253554591426 \n",
            "Epoch:  1\n",
            "54/400.0 loss: 0.6917781808159568 \n",
            "Epoch:  1\n",
            "55/400.0 loss: 0.6914943903684616 \n",
            "Epoch:  1\n",
            "56/400.0 loss: 0.6904589251468056 \n",
            "Epoch:  1\n",
            "57/400.0 loss: 0.6898664688241893 \n",
            "Epoch:  1\n",
            "58/400.0 loss: 0.6888661869501663 \n",
            "Epoch:  1\n",
            "59/400.0 loss: 0.6881988565127055 \n",
            "Epoch:  1\n",
            "60/400.0 loss: 0.6858399559239872 \n",
            "Epoch:  1\n",
            "61/400.0 loss: 0.6866327918344929 \n",
            "Epoch:  1\n",
            "62/400.0 loss: 0.6853519280751547 \n",
            "Epoch:  1\n",
            "63/400.0 loss: 0.6841233251616359 \n",
            "Epoch:  1\n",
            "64/400.0 loss: 0.6856719787304218 \n",
            "Epoch:  1\n",
            "65/400.0 loss: 0.6853922533266472 \n",
            "Epoch:  1\n",
            "66/400.0 loss: 0.6844119509654258 \n",
            "Epoch:  1\n",
            "67/400.0 loss: 0.6845178314868141 \n",
            "Epoch:  1\n",
            "68/400.0 loss: 0.6827202698458796 \n",
            "Epoch:  1\n",
            "69/400.0 loss: 0.6815221854618617 \n",
            "Epoch:  1\n",
            "70/400.0 loss: 0.6814333670575854 \n",
            "Epoch:  1\n",
            "71/400.0 loss: 0.6803607741991679 \n",
            "Epoch:  1\n",
            "72/400.0 loss: 0.6785559695060939 \n",
            "Epoch:  1\n",
            "73/400.0 loss: 0.6797316348230517 \n",
            "Epoch:  1\n",
            "74/400.0 loss: 0.6805876183509827 \n",
            "Epoch:  1\n",
            "75/400.0 loss: 0.680428254761194 \n",
            "Epoch:  1\n",
            "76/400.0 loss: 0.6811626770279624 \n",
            "Epoch:  1\n",
            "77/400.0 loss: 0.6820107797781626 \n",
            "Epoch:  1\n",
            "78/400.0 loss: 0.682136482830289 \n",
            "Epoch:  1\n",
            "79/400.0 loss: 0.6817910604178905 \n",
            "Epoch:  1\n",
            "80/400.0 loss: 0.6805163776433026 \n",
            "Epoch:  1\n",
            "81/400.0 loss: 0.6783275865926975 \n",
            "Epoch:  1\n",
            "82/400.0 loss: 0.6760919065360563 \n",
            "Epoch:  1\n",
            "83/400.0 loss: 0.6763861519949776 \n",
            "Epoch:  1\n",
            "84/400.0 loss: 0.6773151509902057 \n",
            "Epoch:  1\n",
            "85/400.0 loss: 0.6777482601099236 \n",
            "Epoch:  1\n",
            "86/400.0 loss: 0.6776698375570362 \n",
            "Epoch:  1\n",
            "87/400.0 loss: 0.6791657818989321 \n",
            "Epoch:  1\n",
            "88/400.0 loss: 0.67827838726258 \n",
            "Epoch:  1\n",
            "89/400.0 loss: 0.6773426036039988 \n",
            "Epoch:  1\n",
            "90/400.0 loss: 0.6756129369630919 \n",
            "Epoch:  1\n",
            "91/400.0 loss: 0.6744251588116521 \n",
            "Epoch:  1\n",
            "92/400.0 loss: 0.6743282182242281 \n",
            "Epoch:  1\n",
            "93/400.0 loss: 0.6740939813725492 \n",
            "Epoch:  1\n",
            "94/400.0 loss: 0.6745426824218348 \n",
            "Epoch:  1\n",
            "95/400.0 loss: 0.6745311450213194 \n",
            "Epoch:  1\n",
            "96/400.0 loss: 0.673753076607419 \n",
            "Epoch:  1\n",
            "97/400.0 loss: 0.675499826669693 \n",
            "Epoch:  1\n",
            "98/400.0 loss: 0.6763232765775739 \n",
            "Epoch:  1\n",
            "99/400.0 loss: 0.6750334042310715 \n",
            "Epoch:  1\n",
            "100/400.0 loss: 0.6749743353022207 \n",
            "Epoch:  1\n",
            "101/400.0 loss: 0.6760901358782077 \n",
            "Epoch:  1\n",
            "102/400.0 loss: 0.6729449048204329 \n",
            "Epoch:  1\n",
            "103/400.0 loss: 0.6717853961655726 \n",
            "Epoch:  1\n",
            "104/400.0 loss: 0.6758102590129489 \n",
            "Epoch:  1\n",
            "105/400.0 loss: 0.6766514601010196 \n",
            "Epoch:  1\n",
            "106/400.0 loss: 0.6779191485632245 \n",
            "Epoch:  1\n",
            "107/400.0 loss: 0.6778190580231173 \n",
            "Epoch:  1\n",
            "108/400.0 loss: 0.6784478581826622 \n",
            "Epoch:  1\n",
            "109/400.0 loss: 0.6780089294368571 \n",
            "Epoch:  1\n",
            "110/400.0 loss: 0.6795817004130768 \n",
            "Epoch:  1\n",
            "111/400.0 loss: 0.6779054070689848 \n",
            "Epoch:  1\n",
            "112/400.0 loss: 0.677450182954822 \n",
            "Epoch:  1\n",
            "113/400.0 loss: 0.677106909323157 \n",
            "Epoch:  1\n",
            "114/400.0 loss: 0.6758606742257657 \n",
            "Epoch:  1\n",
            "115/400.0 loss: 0.6758473554048045 \n",
            "Epoch:  1\n",
            "116/400.0 loss: 0.6758624001955374 \n",
            "Epoch:  1\n",
            "117/400.0 loss: 0.674528391431954 \n",
            "Epoch:  1\n",
            "118/400.0 loss: 0.6741953134035864 \n",
            "Epoch:  1\n",
            "119/400.0 loss: 0.6740531700352828 \n",
            "Epoch:  1\n",
            "120/400.0 loss: 0.6740511584380442 \n",
            "Epoch:  1\n",
            "121/400.0 loss: 0.6752530016371461 \n",
            "Epoch:  1\n",
            "122/400.0 loss: 0.6756914856472636 \n",
            "Epoch:  1\n",
            "123/400.0 loss: 0.6751497058618453 \n",
            "Epoch:  1\n",
            "124/400.0 loss: 0.6745347311496734 \n",
            "Epoch:  1\n",
            "125/400.0 loss: 0.6738180435366101 \n",
            "Epoch:  1\n",
            "126/400.0 loss: 0.6732765311800589 \n",
            "Epoch:  1\n",
            "127/400.0 loss: 0.6737867293413728 \n",
            "Epoch:  1\n",
            "128/400.0 loss: 0.6734033816082533 \n",
            "Epoch:  1\n",
            "129/400.0 loss: 0.6735367025320347 \n",
            "Epoch:  1\n",
            "130/400.0 loss: 0.6725133236582953 \n",
            "Epoch:  1\n",
            "131/400.0 loss: 0.6717082368153514 \n",
            "Epoch:  1\n",
            "132/400.0 loss: 0.6725256700712935 \n",
            "Epoch:  1\n",
            "133/400.0 loss: 0.6728473561468409 \n",
            "Epoch:  1\n",
            "134/400.0 loss: 0.6736365607491246 \n",
            "Epoch:  1\n",
            "135/400.0 loss: 0.6731599567129332 \n",
            "Epoch:  1\n",
            "136/400.0 loss: 0.6756321824815151 \n",
            "Epoch:  1\n",
            "137/400.0 loss: 0.6748861789271452 \n",
            "Epoch:  1\n",
            "138/400.0 loss: 0.6747507669514031 \n",
            "Epoch:  1\n",
            "139/400.0 loss: 0.6740634328552655 \n",
            "Epoch:  1\n",
            "140/400.0 loss: 0.6732212501637479 \n",
            "Epoch:  1\n",
            "141/400.0 loss: 0.6724612702366332 \n",
            "Epoch:  1\n",
            "142/400.0 loss: 0.6719564389098774 \n",
            "Epoch:  1\n",
            "143/400.0 loss: 0.6715479259275727 \n",
            "Epoch:  1\n",
            "144/400.0 loss: 0.6710339540037615 \n",
            "Epoch:  1\n",
            "145/400.0 loss: 0.6705421186881523 \n",
            "Epoch:  1\n",
            "146/400.0 loss: 0.6702430161083637 \n",
            "Epoch:  1\n",
            "147/400.0 loss: 0.6698863701643171 \n",
            "Epoch:  1\n",
            "148/400.0 loss: 0.6694868973037541 \n",
            "Epoch:  1\n",
            "149/400.0 loss: 0.6694114742676417 \n",
            "Epoch:  1\n",
            "150/400.0 loss: 0.66892814498074 \n",
            "Epoch:  1\n",
            "151/400.0 loss: 0.6681360674923972 \n",
            "Epoch:  1\n",
            "152/400.0 loss: 0.669723882199892 \n",
            "Epoch:  1\n",
            "153/400.0 loss: 0.669319404603599 \n",
            "Epoch:  1\n",
            "154/400.0 loss: 0.668675091766542 \n",
            "Epoch:  1\n",
            "155/400.0 loss: 0.6685550573926705 \n",
            "Epoch:  1\n",
            "156/400.0 loss: 0.6679292630617786 \n",
            "Epoch:  1\n",
            "157/400.0 loss: 0.6669830953395819 \n",
            "Epoch:  1\n",
            "158/400.0 loss: 0.6676974275951866 \n",
            "Epoch:  1\n",
            "159/400.0 loss: 0.6681955428794026 \n",
            "Epoch:  1\n",
            "160/400.0 loss: 0.6684666522171187 \n",
            "Epoch:  1\n",
            "161/400.0 loss: 0.6683401191308175 \n",
            "Epoch:  1\n",
            "162/400.0 loss: 0.6682409931179936 \n",
            "Epoch:  1\n",
            "163/400.0 loss: 0.6685484849461695 \n",
            "Epoch:  1\n",
            "164/400.0 loss: 0.6683665432713248 \n",
            "Epoch:  1\n",
            "165/400.0 loss: 0.6679768725691071 \n",
            "Epoch:  1\n",
            "166/400.0 loss: 0.667746866356113 \n",
            "Epoch:  1\n",
            "167/400.0 loss: 0.6679213158786297 \n",
            "Epoch:  1\n",
            "168/400.0 loss: 0.6680303633918424 \n",
            "Epoch:  1\n",
            "169/400.0 loss: 0.6686639545594945 \n",
            "Epoch:  1\n",
            "170/400.0 loss: 0.6684032753545638 \n",
            "Epoch:  1\n",
            "171/400.0 loss: 0.6685049895976864 \n",
            "Epoch:  1\n",
            "172/400.0 loss: 0.6687512644109009 \n",
            "Epoch:  1\n",
            "173/400.0 loss: 0.6687985526761789 \n",
            "Epoch:  1\n",
            "174/400.0 loss: 0.6689753057275499 \n",
            "Epoch:  1\n",
            "175/400.0 loss: 0.6689624083651737 \n",
            "Epoch:  1\n",
            "176/400.0 loss: 0.6688429644215579 \n",
            "Epoch:  1\n",
            "177/400.0 loss: 0.668692637193069 \n",
            "Epoch:  1\n",
            "178/400.0 loss: 0.6688504866714584 \n",
            "Epoch:  1\n",
            "179/400.0 loss: 0.6685925991998778 \n",
            "Epoch:  1\n",
            "180/400.0 loss: 0.6682329545034229 \n",
            "Epoch:  1\n",
            "181/400.0 loss: 0.6668661199100725 \n",
            "Epoch:  1\n",
            "182/400.0 loss: 0.6671647838230341 \n",
            "Epoch:  1\n",
            "183/400.0 loss: 0.6671147257413553 \n",
            "Epoch:  1\n",
            "184/400.0 loss: 0.6673597846482251 \n",
            "Epoch:  1\n",
            "185/400.0 loss: 0.6670145868293701 \n",
            "Epoch:  1\n",
            "186/400.0 loss: 0.6652479415590112 \n",
            "Epoch:  1\n",
            "187/400.0 loss: 0.6662845831919224 \n",
            "Epoch:  1\n",
            "188/400.0 loss: 0.6658128529944748 \n",
            "Epoch:  1\n",
            "189/400.0 loss: 0.6657601442776229 \n",
            "Epoch:  1\n",
            "190/400.0 loss: 0.6655830733126995 \n",
            "Epoch:  1\n",
            "191/400.0 loss: 0.6659834585152566 \n",
            "Epoch:  1\n",
            "192/400.0 loss: 0.6673085271076835 \n",
            "Epoch:  1\n",
            "193/400.0 loss: 0.6664416667112371 \n",
            "Epoch:  1\n",
            "194/400.0 loss: 0.6662407795588176 \n",
            "Epoch:  1\n",
            "195/400.0 loss: 0.6670845394231835 \n",
            "Epoch:  1\n",
            "196/400.0 loss: 0.6661732366242384 \n",
            "Epoch:  1\n",
            "197/400.0 loss: 0.6653826844812644 \n",
            "Epoch:  1\n",
            "198/400.0 loss: 0.6650814339144147 \n",
            "Epoch:  1\n",
            "199/400.0 loss: 0.6649083858728408 \n",
            "Epoch:  1\n",
            "200/400.0 loss: 0.6653047758548414 \n",
            "Epoch:  1\n",
            "201/400.0 loss: 0.6644598000710553 \n",
            "Epoch:  1\n",
            "202/400.0 loss: 0.6641291808612241 \n",
            "Epoch:  1\n",
            "203/400.0 loss: 0.6643518583447325 \n",
            "Epoch:  1\n",
            "204/400.0 loss: 0.6643969477676763 \n",
            "Epoch:  1\n",
            "205/400.0 loss: 0.6641889145073382 \n",
            "Epoch:  1\n",
            "206/400.0 loss: 0.6648800004507609 \n",
            "Epoch:  1\n",
            "207/400.0 loss: 0.6643194845662668 \n",
            "Epoch:  1\n",
            "208/400.0 loss: 0.6643955995591634 \n",
            "Epoch:  1\n",
            "209/400.0 loss: 0.6639285201118106 \n",
            "Epoch:  1\n",
            "210/400.0 loss: 0.6642159836552154 \n",
            "Epoch:  1\n",
            "211/400.0 loss: 0.6634228086134173 \n",
            "Epoch:  1\n",
            "212/400.0 loss: 0.6625396735231641 \n",
            "Epoch:  1\n",
            "213/400.0 loss: 0.6613834600582301 \n",
            "Epoch:  1\n",
            "214/400.0 loss: 0.6624752421711766 \n",
            "Epoch:  1\n",
            "215/400.0 loss: 0.6614764040267026 \n",
            "Epoch:  1\n",
            "216/400.0 loss: 0.661073597345484 \n",
            "Epoch:  1\n",
            "217/400.0 loss: 0.6605040931373561 \n",
            "Epoch:  1\n",
            "218/400.0 loss: 0.6607751157730137 \n",
            "Epoch:  1\n",
            "219/400.0 loss: 0.6612700280818072 \n",
            "Epoch:  1\n",
            "220/400.0 loss: 0.6611005674659937 \n",
            "Epoch:  1\n",
            "221/400.0 loss: 0.660730737286645 \n",
            "Epoch:  1\n",
            "222/400.0 loss: 0.6601475356940196 \n",
            "Epoch:  1\n",
            "223/400.0 loss: 0.6598934799964938 \n",
            "Epoch:  1\n",
            "224/400.0 loss: 0.6589695117208693 \n",
            "Epoch:  1\n",
            "225/400.0 loss: 0.6583947982408304 \n",
            "Epoch:  1\n",
            "226/400.0 loss: 0.6586802165938894 \n",
            "Epoch:  1\n",
            "227/400.0 loss: 0.6589969812255156 \n",
            "Epoch:  1\n",
            "228/400.0 loss: 0.658614785129847 \n",
            "Epoch:  1\n",
            "229/400.0 loss: 0.6584898961626965 \n",
            "Epoch:  1\n",
            "230/400.0 loss: 0.6592809981081909 \n",
            "Epoch:  1\n",
            "231/400.0 loss: 0.6590676520918978 \n",
            "Epoch:  1\n",
            "232/400.0 loss: 0.6585993490505628 \n",
            "Epoch:  1\n",
            "233/400.0 loss: 0.6592103013625512 \n",
            "Epoch:  1\n",
            "234/400.0 loss: 0.6585252657849738 \n",
            "Epoch:  1\n",
            "235/400.0 loss: 0.6583475606926417 \n",
            "Epoch:  1\n",
            "236/400.0 loss: 0.6584649905876772 \n",
            "Epoch:  1\n",
            "237/400.0 loss: 0.657871260362513 \n",
            "Epoch:  1\n",
            "238/400.0 loss: 0.6576440473979487 \n",
            "Epoch:  1\n",
            "239/400.0 loss: 0.6570008546113968 \n",
            "Epoch:  1\n",
            "240/400.0 loss: 0.6567348281377579 \n",
            "Epoch:  1\n",
            "241/400.0 loss: 0.6572528407593404 \n",
            "Epoch:  1\n",
            "242/400.0 loss: 0.6575065635359336 \n",
            "Epoch:  1\n",
            "243/400.0 loss: 0.6568571376751681 \n",
            "Epoch:  1\n",
            "244/400.0 loss: 0.6566970658545591 \n",
            "Epoch:  1\n",
            "245/400.0 loss: 0.6560389079698702 \n",
            "Epoch:  1\n",
            "246/400.0 loss: 0.6550273631024457 \n",
            "Epoch:  1\n",
            "247/400.0 loss: 0.6557499878108501 \n",
            "Epoch:  1\n",
            "248/400.0 loss: 0.6551618967429701 \n",
            "Epoch:  1\n",
            "249/400.0 loss: 0.6559511984586716 \n",
            "Epoch:  1\n",
            "250/400.0 loss: 0.6558796422652514 \n",
            "Epoch:  1\n",
            "251/400.0 loss: 0.6551567506459024 \n",
            "Epoch:  1\n",
            "252/400.0 loss: 0.6562734925935391 \n",
            "Epoch:  1\n",
            "253/400.0 loss: 0.6564603465513921 \n",
            "Epoch:  1\n",
            "254/400.0 loss: 0.655871733380299 \n",
            "Epoch:  1\n",
            "255/400.0 loss: 0.6559299387736246 \n",
            "Epoch:  1\n",
            "256/400.0 loss: 0.6557925901292363 \n",
            "Epoch:  1\n",
            "257/400.0 loss: 0.6558857891679735 \n",
            "Epoch:  1\n",
            "258/400.0 loss: 0.65554032880367 \n",
            "Epoch:  1\n",
            "259/400.0 loss: 0.6562954303163748 \n",
            "Epoch:  1\n",
            "260/400.0 loss: 0.6564775062475168 \n",
            "Epoch:  1\n",
            "261/400.0 loss: 0.6564731683212383 \n",
            "Epoch:  1\n",
            "262/400.0 loss: 0.6565193140688051 \n",
            "Epoch:  1\n",
            "263/400.0 loss: 0.6567818266198491 \n",
            "Epoch:  1\n",
            "264/400.0 loss: 0.6565290641109899 \n",
            "Epoch:  1\n",
            "265/400.0 loss: 0.6568228036613393 \n",
            "Epoch:  1\n",
            "266/400.0 loss: 0.6567274130015784 \n",
            "Epoch:  1\n",
            "267/400.0 loss: 0.6567895077724955 \n",
            "Epoch:  1\n",
            "268/400.0 loss: 0.6568979770499092 \n",
            "Epoch:  1\n",
            "269/400.0 loss: 0.6572236934193858 \n",
            "Epoch:  1\n",
            "270/400.0 loss: 0.6569668442780682 \n",
            "Epoch:  1\n",
            "271/400.0 loss: 0.6570024995461983 \n",
            "Epoch:  1\n",
            "272/400.0 loss: 0.656723120601186 \n",
            "Epoch:  1\n",
            "273/400.0 loss: 0.6568254442328084 \n",
            "Epoch:  1\n",
            "274/400.0 loss: 0.6566078351844441 \n",
            "Epoch:  1\n",
            "275/400.0 loss: 0.6566044348089591 \n",
            "Epoch:  1\n",
            "276/400.0 loss: 0.6564359601439121 \n",
            "Epoch:  1\n",
            "277/400.0 loss: 0.6569449448113819 \n",
            "Epoch:  1\n",
            "278/400.0 loss: 0.6571196848559978 \n",
            "Epoch:  1\n",
            "279/400.0 loss: 0.6563305221498013 \n",
            "Epoch:  1\n",
            "280/400.0 loss: 0.6568914296576137 \n",
            "Epoch:  1\n",
            "281/400.0 loss: 0.6570595347500862 \n",
            "Epoch:  1\n",
            "282/400.0 loss: 0.6571619572782685 \n",
            "Epoch:  1\n",
            "283/400.0 loss: 0.6573687520035556 \n",
            "Epoch:  1\n",
            "284/400.0 loss: 0.6569706530947435 \n",
            "Epoch:  1\n",
            "285/400.0 loss: 0.6572943849788679 \n",
            "Epoch:  1\n",
            "286/400.0 loss: 0.6570130708117934 \n",
            "Epoch:  1\n",
            "287/400.0 loss: 0.656464098331829 \n",
            "Epoch:  1\n",
            "288/400.0 loss: 0.6570140631759868 \n",
            "Epoch:  1\n",
            "289/400.0 loss: 0.6571659006949129 \n",
            "Epoch:  1\n",
            "290/400.0 loss: 0.6574202428773507 \n",
            "Epoch:  1\n",
            "291/400.0 loss: 0.6572837336626771 \n",
            "Epoch:  1\n",
            "292/400.0 loss: 0.658137501201532 \n",
            "Epoch:  1\n",
            "293/400.0 loss: 0.6584415503707873 \n",
            "Epoch:  1\n",
            "294/400.0 loss: 0.6579145002163063 \n",
            "Epoch:  1\n",
            "295/400.0 loss: 0.657663827913033 \n",
            "Epoch:  1\n",
            "296/400.0 loss: 0.657509838390832 \n",
            "Epoch:  1\n",
            "297/400.0 loss: 0.6573810502386733 \n",
            "Epoch:  1\n",
            "298/400.0 loss: 0.6576117473501825 \n",
            "Epoch:  1\n",
            "299/400.0 loss: 0.6578428527712822 \n",
            "Epoch:  1\n",
            "300/400.0 loss: 0.657508634748649 \n",
            "Epoch:  1\n",
            "301/400.0 loss: 0.6571111407698385 \n",
            "Epoch:  1\n",
            "302/400.0 loss: 0.6573132183095409 \n",
            "Epoch:  1\n",
            "303/400.0 loss: 0.6570835081174186 \n",
            "Epoch:  1\n",
            "304/400.0 loss: 0.6573934819854674 \n",
            "Epoch:  1\n",
            "305/400.0 loss: 0.6572635231259601 \n",
            "Epoch:  1\n",
            "306/400.0 loss: 0.6577374732261372 \n",
            "Epoch:  1\n",
            "307/400.0 loss: 0.6574948599392717 \n",
            "Epoch:  1\n",
            "308/400.0 loss: 0.6573723989590087 \n",
            "Epoch:  1\n",
            "309/400.0 loss: 0.6580805492977942 \n",
            "Epoch:  1\n",
            "310/400.0 loss: 0.657514503051997 \n",
            "Epoch:  1\n",
            "311/400.0 loss: 0.6573453055551419 \n",
            "Epoch:  1\n",
            "312/400.0 loss: 0.6575860389695761 \n",
            "Epoch:  1\n",
            "313/400.0 loss: 0.6579698374506774 \n",
            "Epoch:  1\n",
            "314/400.0 loss: 0.658093386699283 \n",
            "Epoch:  1\n",
            "315/400.0 loss: 0.6583023881421813 \n",
            "Epoch:  1\n",
            "316/400.0 loss: 0.6579716738654235 \n",
            "Epoch:  1\n",
            "317/400.0 loss: 0.6581487306071527 \n",
            "Epoch:  1\n",
            "318/400.0 loss: 0.6580719461074818 \n",
            "Epoch:  1\n",
            "319/400.0 loss: 0.6579263157211244 \n",
            "Epoch:  1\n",
            "320/400.0 loss: 0.6577904860364314 \n",
            "Epoch:  1\n",
            "321/400.0 loss: 0.6576967040389221 \n",
            "Epoch:  1\n",
            "322/400.0 loss: 0.6567789820879236 \n",
            "Epoch:  1\n",
            "323/400.0 loss: 0.656714323218222 \n",
            "Epoch:  1\n",
            "324/400.0 loss: 0.6564275658130646 \n",
            "Epoch:  1\n",
            "325/400.0 loss: 0.6560946775177505 \n",
            "Epoch:  1\n",
            "326/400.0 loss: 0.6555597283606864 \n",
            "Epoch:  1\n",
            "327/400.0 loss: 0.6549648020143916 \n",
            "Epoch:  1\n",
            "328/400.0 loss: 0.6547243612334359 \n",
            "Epoch:  1\n",
            "329/400.0 loss: 0.6545828626914458 \n",
            "Epoch:  1\n",
            "330/400.0 loss: 0.6558638212363885 \n",
            "Epoch:  1\n",
            "331/400.0 loss: 0.6557716765856169 \n",
            "Epoch:  1\n",
            "332/400.0 loss: 0.6553921777385849 \n",
            "Epoch:  1\n",
            "333/400.0 loss: 0.6548089693763299 \n",
            "Epoch:  1\n",
            "334/400.0 loss: 0.6551506542447788 \n",
            "Epoch:  1\n",
            "335/400.0 loss: 0.6548075099431333 \n",
            "Epoch:  1\n",
            "336/400.0 loss: 0.655067859842091 \n",
            "Epoch:  1\n",
            "337/400.0 loss: 0.6548330110205701 \n",
            "Epoch:  1\n",
            "338/400.0 loss: 0.6537882198626312 \n",
            "Epoch:  1\n",
            "339/400.0 loss: 0.6540062471347696 \n",
            "Epoch:  1\n",
            "340/400.0 loss: 0.6544175960800864 \n",
            "Epoch:  1\n",
            "341/400.0 loss: 0.6537077205571514 \n",
            "Epoch:  1\n",
            "342/400.0 loss: 0.653704856470792 \n",
            "Epoch:  1\n",
            "343/400.0 loss: 0.653407770360625 \n",
            "Epoch:  1\n",
            "344/400.0 loss: 0.6538001017294068 \n",
            "Epoch:  1\n",
            "345/400.0 loss: 0.6537025576037478 \n",
            "Epoch:  1\n",
            "346/400.0 loss: 0.6533518960908785 \n",
            "Epoch:  1\n",
            "347/400.0 loss: 0.6532631047155665 \n",
            "Epoch:  1\n",
            "348/400.0 loss: 0.6533433017894669 \n",
            "Epoch:  1\n",
            "349/400.0 loss: 0.6532904423986162 \n",
            "Epoch:  1\n",
            "350/400.0 loss: 0.6541774909720461 \n",
            "Epoch:  1\n",
            "351/400.0 loss: 0.6545701279220256 \n",
            "Epoch:  1\n",
            "352/400.0 loss: 0.6546085103713082 \n",
            "Epoch:  1\n",
            "353/400.0 loss: 0.6550749745746117 \n",
            "Epoch:  1\n",
            "354/400.0 loss: 0.6547238089668919 \n",
            "Epoch:  1\n",
            "355/400.0 loss: 0.655289490403754 \n",
            "Epoch:  1\n",
            "356/400.0 loss: 0.6555196669589237 \n",
            "Epoch:  1\n",
            "357/400.0 loss: 0.6553558032938888 \n",
            "Epoch:  1\n",
            "358/400.0 loss: 0.6554547544973475 \n",
            "Epoch:  1\n",
            "359/400.0 loss: 0.6553784117102623 \n",
            "Epoch:  1\n",
            "360/400.0 loss: 0.655316594399904 \n",
            "Epoch:  1\n",
            "361/400.0 loss: 0.6552259959897943 \n",
            "Epoch:  1\n",
            "362/400.0 loss: 0.6551216471293742 \n",
            "Epoch:  1\n",
            "363/400.0 loss: 0.6551749822530117 \n",
            "Epoch:  1\n",
            "364/400.0 loss: 0.6553282879803278 \n",
            "Epoch:  1\n",
            "365/400.0 loss: 0.6550182545445656 \n",
            "Epoch:  1\n",
            "366/400.0 loss: 0.6549997354073486 \n",
            "Epoch:  1\n",
            "367/400.0 loss: 0.6547819398667502 \n",
            "Epoch:  1\n",
            "368/400.0 loss: 0.6550457081820583 \n",
            "Epoch:  1\n",
            "369/400.0 loss: 0.655123827103022 \n",
            "Epoch:  1\n",
            "370/400.0 loss: 0.6552000354242453 \n",
            "Epoch:  1\n",
            "371/400.0 loss: 0.6550328999116857 \n",
            "Epoch:  1\n",
            "372/400.0 loss: 0.6553573844899441 \n",
            "Epoch:  1\n",
            "373/400.0 loss: 0.6554786457734949 \n",
            "Epoch:  1\n",
            "374/400.0 loss: 0.6555737393697103 \n",
            "Epoch:  1\n",
            "375/400.0 loss: 0.6552927893527011 \n",
            "Epoch:  1\n",
            "376/400.0 loss: 0.6554043131734711 \n",
            "Epoch:  1\n",
            "377/400.0 loss: 0.6554253892923789 \n",
            "Epoch:  1\n",
            "378/400.0 loss: 0.6555185987955662 \n",
            "Epoch:  1\n",
            "379/400.0 loss: 0.6557384663506558 \n",
            "Epoch:  1\n",
            "380/400.0 loss: 0.6556590754841882 \n",
            "Epoch:  1\n",
            "381/400.0 loss: 0.6559771439791974 \n",
            "Epoch:  1\n",
            "382/400.0 loss: 0.6560836862335006 \n",
            "Epoch:  1\n",
            "383/400.0 loss: 0.6566374267761906 \n",
            "Epoch:  1\n",
            "384/400.0 loss: 0.6565346950060361 \n",
            "Epoch:  1\n",
            "385/400.0 loss: 0.6565917745773039 \n",
            "Epoch:  1\n",
            "386/400.0 loss: 0.6563105541606282 \n",
            "Epoch:  1\n",
            "387/400.0 loss: 0.656187091752426 \n",
            "Epoch:  1\n",
            "388/400.0 loss: 0.6563189359128015 \n",
            "Epoch:  1\n",
            "389/400.0 loss: 0.6562206358481676 \n",
            "Epoch:  1\n",
            "390/400.0 loss: 0.6562377633646016 \n",
            "Epoch:  1\n",
            "391/400.0 loss: 0.6561976900818397 \n",
            "Epoch:  1\n",
            "392/400.0 loss: 0.6562226340364257 \n",
            "Epoch:  1\n",
            "393/400.0 loss: 0.6563663499306907 \n",
            "Epoch:  1\n",
            "394/400.0 loss: 0.6563882266418843 \n",
            "Epoch:  1\n",
            "395/400.0 loss: 0.656194945477476 \n",
            "Epoch:  1\n",
            "396/400.0 loss: 0.6558693223996487 \n",
            "Epoch:  1\n",
            "397/400.0 loss: 0.655743420872856 \n",
            "Epoch:  1\n",
            "398/400.0 loss: 0.6557314609525198 \n",
            "Epoch:  1\n",
            "399/400.0 loss: 0.6556838689744473 \n",
            "Epoch:  2\n",
            "0/400.0 loss: 0.6722208261489868 \n",
            "Epoch:  2\n",
            "1/400.0 loss: 0.6797696650028229 \n",
            "Epoch:  2\n",
            "2/400.0 loss: 0.6339348355929056 \n",
            "Epoch:  2\n",
            "3/400.0 loss: 0.6195126324892044 \n",
            "Epoch:  2\n",
            "4/400.0 loss: 0.5849391698837281 \n",
            "Epoch:  2\n",
            "5/400.0 loss: 0.5783608456452688 \n",
            "Epoch:  2\n",
            "6/400.0 loss: 0.5876333543232509 \n",
            "Epoch:  2\n",
            "7/400.0 loss: 0.5786412060260773 \n",
            "Epoch:  2\n",
            "8/400.0 loss: 0.5630611313713921 \n",
            "Epoch:  2\n",
            "9/400.0 loss: 0.5877297937870025 \n",
            "Epoch:  2\n",
            "10/400.0 loss: 0.6043620163744147 \n",
            "Epoch:  2\n",
            "11/400.0 loss: 0.5977854977051417 \n",
            "Epoch:  2\n",
            "12/400.0 loss: 0.5898796136562641 \n",
            "Epoch:  2\n",
            "13/400.0 loss: 0.5920675482068744 \n",
            "Epoch:  2\n",
            "14/400.0 loss: 0.606343146165212 \n",
            "Epoch:  2\n",
            "15/400.0 loss: 0.5961869470775127 \n",
            "Epoch:  2\n",
            "16/400.0 loss: 0.595431247178246 \n",
            "Epoch:  2\n",
            "17/400.0 loss: 0.6044936809274886 \n",
            "Epoch:  2\n",
            "18/400.0 loss: 0.5957990727926555 \n",
            "Epoch:  2\n",
            "19/400.0 loss: 0.5857230424880981 \n",
            "Epoch:  2\n",
            "20/400.0 loss: 0.5911880220685687 \n",
            "Epoch:  2\n",
            "21/400.0 loss: 0.5878924510695718 \n",
            "Epoch:  2\n",
            "22/400.0 loss: 0.5801154595354329 \n",
            "Epoch:  2\n",
            "23/400.0 loss: 0.573991421610117 \n",
            "Epoch:  2\n",
            "24/400.0 loss: 0.5664973056316376 \n",
            "Epoch:  2\n",
            "25/400.0 loss: 0.5573748911802585 \n",
            "Epoch:  2\n",
            "26/400.0 loss: 0.5564508184238717 \n",
            "Epoch:  2\n",
            "27/400.0 loss: 0.5417472879801478 \n",
            "Epoch:  2\n",
            "28/400.0 loss: 0.5522057342118231 \n",
            "Epoch:  2\n",
            "29/400.0 loss: 0.5531134138504664 \n",
            "Epoch:  2\n",
            "30/400.0 loss: 0.5442272232424828 \n",
            "Epoch:  2\n",
            "31/400.0 loss: 0.5466587729752064 \n",
            "Epoch:  2\n",
            "32/400.0 loss: 0.5472238695982731 \n",
            "Epoch:  2\n",
            "33/400.0 loss: 0.5402080031002269 \n",
            "Epoch:  2\n",
            "34/400.0 loss: 0.5289109877177647 \n",
            "Epoch:  2\n",
            "35/400.0 loss: 0.5348826944828033 \n",
            "Epoch:  2\n",
            "36/400.0 loss: 0.5410922379107088 \n",
            "Epoch:  2\n",
            "37/400.0 loss: 0.5492451645826039 \n",
            "Epoch:  2\n",
            "38/400.0 loss: 0.5505661674034901 \n",
            "Epoch:  2\n",
            "39/400.0 loss: 0.5482659757137298 \n",
            "Epoch:  2\n",
            "40/400.0 loss: 0.5430012345314026 \n",
            "Epoch:  2\n",
            "41/400.0 loss: 0.5520831346511841 \n",
            "Epoch:  2\n",
            "42/400.0 loss: 0.5554049098214437 \n",
            "Epoch:  2\n",
            "43/400.0 loss: 0.5604664006016471 \n",
            "Epoch:  2\n",
            "44/400.0 loss: 0.5580768797132704 \n",
            "Epoch:  2\n",
            "45/400.0 loss: 0.5560166408186373 \n",
            "Epoch:  2\n",
            "46/400.0 loss: 0.555815799439207 \n",
            "Epoch:  2\n",
            "47/400.0 loss: 0.553643086925149 \n",
            "Epoch:  2\n",
            "48/400.0 loss: 0.5533280780120772 \n",
            "Epoch:  2\n",
            "49/400.0 loss: 0.5584682494401931 \n",
            "Epoch:  2\n",
            "50/400.0 loss: 0.5674903468758452 \n",
            "Epoch:  2\n",
            "51/400.0 loss: 0.5670746857157121 \n",
            "Epoch:  2\n",
            "52/400.0 loss: 0.5632291340603018 \n",
            "Epoch:  2\n",
            "53/400.0 loss: 0.565530276408902 \n",
            "Epoch:  2\n",
            "54/400.0 loss: 0.5683774324980649 \n",
            "Epoch:  2\n",
            "55/400.0 loss: 0.5694604979029724 \n",
            "Epoch:  2\n",
            "56/400.0 loss: 0.5735447401540321 \n",
            "Epoch:  2\n",
            "57/400.0 loss: 0.5725993015642824 \n",
            "Epoch:  2\n",
            "58/400.0 loss: 0.5714829892425214 \n",
            "Epoch:  2\n",
            "59/400.0 loss: 0.569332379102707 \n",
            "Epoch:  2\n",
            "60/400.0 loss: 0.5701807326957827 \n",
            "Epoch:  2\n",
            "61/400.0 loss: 0.5725356013544144 \n",
            "Epoch:  2\n",
            "62/400.0 loss: 0.5723254396801903 \n",
            "Epoch:  2\n",
            "63/400.0 loss: 0.5758007960394025 \n",
            "Epoch:  2\n",
            "64/400.0 loss: 0.5757356854585501 \n",
            "Epoch:  2\n",
            "65/400.0 loss: 0.5770623485247294 \n",
            "Epoch:  2\n",
            "66/400.0 loss: 0.57839035987854 \n",
            "Epoch:  2\n",
            "67/400.0 loss: 0.5760005975470823 \n",
            "Epoch:  2\n",
            "68/400.0 loss: 0.5806232777194701 \n",
            "Epoch:  2\n",
            "69/400.0 loss: 0.5831246478216988 \n",
            "Epoch:  2\n",
            "70/400.0 loss: 0.582686509884579 \n",
            "Epoch:  2\n",
            "71/400.0 loss: 0.5824106724725829 \n",
            "Epoch:  2\n",
            "72/400.0 loss: 0.5798415982559936 \n",
            "Epoch:  2\n",
            "73/400.0 loss: 0.5786822603361027 \n",
            "Epoch:  2\n",
            "74/400.0 loss: 0.5792049022515615 \n",
            "Epoch:  2\n",
            "75/400.0 loss: 0.5822201100619215 \n",
            "Epoch:  2\n",
            "76/400.0 loss: 0.5851918160915375 \n",
            "Epoch:  2\n",
            "77/400.0 loss: 0.5857559606814996 \n",
            "Epoch:  2\n",
            "78/400.0 loss: 0.5880277047428903 \n",
            "Epoch:  2\n",
            "79/400.0 loss: 0.5863660722970963 \n",
            "Epoch:  2\n",
            "80/400.0 loss: 0.5855262691591993 \n",
            "Epoch:  2\n",
            "81/400.0 loss: 0.5858696844519639 \n",
            "Epoch:  2\n",
            "82/400.0 loss: 0.5902386063552765 \n",
            "Epoch:  2\n",
            "83/400.0 loss: 0.5928393779765992 \n",
            "Epoch:  2\n",
            "84/400.0 loss: 0.5922507208936355 \n",
            "Epoch:  2\n",
            "85/400.0 loss: 0.5927480452282484 \n",
            "Epoch:  2\n",
            "86/400.0 loss: 0.5970341734502508 \n",
            "Epoch:  2\n",
            "87/400.0 loss: 0.59823227673769 \n",
            "Epoch:  2\n",
            "88/400.0 loss: 0.5954368248414458 \n",
            "Epoch:  2\n",
            "89/400.0 loss: 0.5962975396050347 \n",
            "Epoch:  2\n",
            "90/400.0 loss: 0.5990860887936184 \n",
            "Epoch:  2\n",
            "91/400.0 loss: 0.6015731180491655 \n",
            "Epoch:  2\n",
            "92/400.0 loss: 0.603522874334807 \n",
            "Epoch:  2\n",
            "93/400.0 loss: 0.602286622245261 \n",
            "Epoch:  2\n",
            "94/400.0 loss: 0.6025226241663882 \n",
            "Epoch:  2\n",
            "95/400.0 loss: 0.6028053152064482 \n",
            "Epoch:  2\n",
            "96/400.0 loss: 0.6019057920298625 \n",
            "Epoch:  2\n",
            "97/400.0 loss: 0.6040811295412025 \n",
            "Epoch:  2\n",
            "98/400.0 loss: 0.6047455680490744 \n",
            "Epoch:  2\n",
            "99/400.0 loss: 0.6044807833433151 \n",
            "Epoch:  2\n",
            "100/400.0 loss: 0.6040103683377257 \n",
            "Epoch:  2\n",
            "101/400.0 loss: 0.6028805027405421 \n",
            "Epoch:  2\n",
            "102/400.0 loss: 0.6028732990176933 \n",
            "Epoch:  2\n",
            "103/400.0 loss: 0.6039727906195017 \n",
            "Epoch:  2\n",
            "104/400.0 loss: 0.6057197074095408 \n",
            "Epoch:  2\n",
            "105/400.0 loss: 0.6062737110088456 \n",
            "Epoch:  2\n",
            "106/400.0 loss: 0.6055104022271165 \n",
            "Epoch:  2\n",
            "107/400.0 loss: 0.6074586502379842 \n",
            "Epoch:  2\n",
            "108/400.0 loss: 0.6076162334429015 \n",
            "Epoch:  2\n",
            "109/400.0 loss: 0.609480917724696 \n",
            "Epoch:  2\n",
            "110/400.0 loss: 0.6110237248846002 \n",
            "Epoch:  2\n",
            "111/400.0 loss: 0.6109937974917037 \n",
            "Epoch:  2\n",
            "112/400.0 loss: 0.611433717793068 \n",
            "Epoch:  2\n",
            "113/400.0 loss: 0.612161789808357 \n",
            "Epoch:  2\n",
            "114/400.0 loss: 0.6127669699814009 \n",
            "Epoch:  2\n",
            "115/400.0 loss: 0.6119693129740912 \n",
            "Epoch:  2\n",
            "116/400.0 loss: 0.6126120480207297 \n",
            "Epoch:  2\n",
            "117/400.0 loss: 0.6129729078482773 \n",
            "Epoch:  2\n",
            "118/400.0 loss: 0.6127130481876245 \n",
            "Epoch:  2\n",
            "119/400.0 loss: 0.6132295134166876 \n",
            "Epoch:  2\n",
            "120/400.0 loss: 0.6129759256997385 \n",
            "Epoch:  2\n",
            "121/400.0 loss: 0.6125386994881709 \n",
            "Epoch:  2\n",
            "122/400.0 loss: 0.6118149313984848 \n",
            "Epoch:  2\n",
            "123/400.0 loss: 0.6115085677273812 \n",
            "Epoch:  2\n",
            "124/400.0 loss: 0.6109315731525421 \n",
            "Epoch:  2\n",
            "125/400.0 loss: 0.611044357929911 \n",
            "Epoch:  2\n",
            "126/400.0 loss: 0.6102875407755844 \n",
            "Epoch:  2\n",
            "127/400.0 loss: 0.6106655944604427 \n",
            "Epoch:  2\n",
            "128/400.0 loss: 0.6140140343544095 \n",
            "Epoch:  2\n",
            "129/400.0 loss: 0.6134603640207877 \n",
            "Epoch:  2\n",
            "130/400.0 loss: 0.6141063377602409 \n",
            "Epoch:  2\n",
            "131/400.0 loss: 0.6133954468550105 \n",
            "Epoch:  2\n",
            "132/400.0 loss: 0.6142840831351459 \n",
            "Epoch:  2\n",
            "133/400.0 loss: 0.614290227863326 \n",
            "Epoch:  2\n",
            "134/400.0 loss: 0.6133396744728088 \n",
            "Epoch:  2\n",
            "135/400.0 loss: 0.6127183643334052 \n",
            "Epoch:  2\n",
            "136/400.0 loss: 0.6122943641495531 \n",
            "Epoch:  2\n",
            "137/400.0 loss: 0.6125862512035646 \n",
            "Epoch:  2\n",
            "138/400.0 loss: 0.6126267575531554 \n",
            "Epoch:  2\n",
            "139/400.0 loss: 0.6126392909458706 \n",
            "Epoch:  2\n",
            "140/400.0 loss: 0.611220565248043 \n",
            "Epoch:  2\n",
            "141/400.0 loss: 0.6100001570204614 \n",
            "Epoch:  2\n",
            "142/400.0 loss: 0.609670756163297 \n",
            "Epoch:  2\n",
            "143/400.0 loss: 0.6100020793577036 \n",
            "Epoch:  2\n",
            "144/400.0 loss: 0.6103287454309134 \n",
            "Epoch:  2\n",
            "145/400.0 loss: 0.6101421995522225 \n",
            "Epoch:  2\n",
            "146/400.0 loss: 0.609047724073436 \n",
            "Epoch:  2\n",
            "147/400.0 loss: 0.6083664308125908 \n",
            "Epoch:  2\n",
            "148/400.0 loss: 0.6083495406896476 \n",
            "Epoch:  2\n",
            "149/400.0 loss: 0.6073509262005488 \n",
            "Epoch:  2\n",
            "150/400.0 loss: 0.6075125267568803 \n",
            "Epoch:  2\n",
            "151/400.0 loss: 0.6079268947635826 \n",
            "Epoch:  2\n",
            "152/400.0 loss: 0.6081250865085452 \n",
            "Epoch:  2\n",
            "153/400.0 loss: 0.6077850389403182 \n",
            "Epoch:  2\n",
            "154/400.0 loss: 0.6074840286085682 \n",
            "Epoch:  2\n",
            "155/400.0 loss: 0.6079859853937075 \n",
            "Epoch:  2\n",
            "156/400.0 loss: 0.6089969294466031 \n",
            "Epoch:  2\n",
            "157/400.0 loss: 0.6097527370799946 \n",
            "Epoch:  2\n",
            "158/400.0 loss: 0.609411246559155 \n",
            "Epoch:  2\n",
            "159/400.0 loss: 0.608903999067843 \n",
            "Epoch:  2\n",
            "160/400.0 loss: 0.6084554648917654 \n",
            "Epoch:  2\n",
            "161/400.0 loss: 0.6099588733028483 \n",
            "Epoch:  2\n",
            "162/400.0 loss: 0.610078940545123 \n",
            "Epoch:  2\n",
            "163/400.0 loss: 0.6103514805436134 \n",
            "Epoch:  2\n",
            "164/400.0 loss: 0.6096314200849244 \n",
            "Epoch:  2\n",
            "165/400.0 loss: 0.6098477562148887 \n",
            "Epoch:  2\n",
            "166/400.0 loss: 0.609197586774826 \n",
            "Epoch:  2\n",
            "167/400.0 loss: 0.609924188859406 \n",
            "Epoch:  2\n",
            "168/400.0 loss: 0.6105824999908018 \n",
            "Epoch:  2\n",
            "169/400.0 loss: 0.6100829392671585 \n",
            "Epoch:  2\n",
            "170/400.0 loss: 0.60938732613597 \n",
            "Epoch:  2\n",
            "171/400.0 loss: 0.6109260464476984 \n",
            "Epoch:  2\n",
            "172/400.0 loss: 0.6104676759656454 \n",
            "Epoch:  2\n",
            "173/400.0 loss: 0.6106517344028101 \n",
            "Epoch:  2\n",
            "174/400.0 loss: 0.6132064657551902 \n",
            "Epoch:  2\n",
            "175/400.0 loss: 0.6123725431547924 \n",
            "Epoch:  2\n",
            "176/400.0 loss: 0.6123208563543309 \n",
            "Epoch:  2\n",
            "177/400.0 loss: 0.6115241671880979 \n",
            "Epoch:  2\n",
            "178/400.0 loss: 0.6132074439658799 \n",
            "Epoch:  2\n",
            "179/400.0 loss: 0.612872203025553 \n",
            "Epoch:  2\n",
            "180/400.0 loss: 0.6140077856693479 \n",
            "Epoch:  2\n",
            "181/400.0 loss: 0.6148942501007856 \n",
            "Epoch:  2\n",
            "182/400.0 loss: 0.6163585142033999 \n",
            "Epoch:  2\n",
            "183/400.0 loss: 0.61637950413253 \n",
            "Epoch:  2\n",
            "184/400.0 loss: 0.6159982831091494 \n",
            "Epoch:  2\n",
            "185/400.0 loss: 0.6156680479805957 \n",
            "Epoch:  2\n",
            "186/400.0 loss: 0.6157722669170502 \n",
            "Epoch:  2\n",
            "187/400.0 loss: 0.6161693326653318 \n",
            "Epoch:  2\n",
            "188/400.0 loss: 0.6152935764461598 \n",
            "Epoch:  2\n",
            "189/400.0 loss: 0.6147950487701517 \n",
            "Epoch:  2\n",
            "190/400.0 loss: 0.6155167310961878 \n",
            "Epoch:  2\n",
            "191/400.0 loss: 0.6156590669415891 \n",
            "Epoch:  2\n",
            "192/400.0 loss: 0.6152179514497055 \n",
            "Epoch:  2\n",
            "193/400.0 loss: 0.6163058405377201 \n",
            "Epoch:  2\n",
            "194/400.0 loss: 0.6162669874154605 \n",
            "Epoch:  2\n",
            "195/400.0 loss: 0.6173507362908247 \n",
            "Epoch:  2\n",
            "196/400.0 loss: 0.6181078361073121 \n",
            "Epoch:  2\n",
            "197/400.0 loss: 0.618782942192723 \n",
            "Epoch:  2\n",
            "198/400.0 loss: 0.6187638342380524 \n",
            "Epoch:  2\n",
            "199/400.0 loss: 0.6183229766786098 \n",
            "Epoch:  2\n",
            "200/400.0 loss: 0.6181654715122868 \n",
            "Epoch:  2\n",
            "201/400.0 loss: 0.6186168446104126 \n",
            "Epoch:  2\n",
            "202/400.0 loss: 0.6189157338858825 \n",
            "Epoch:  2\n",
            "203/400.0 loss: 0.6193805750386387 \n",
            "Epoch:  2\n",
            "204/400.0 loss: 0.6201265601123251 \n",
            "Epoch:  2\n",
            "205/400.0 loss: 0.620471470419643 \n",
            "Epoch:  2\n",
            "206/400.0 loss: 0.6207603640890352 \n",
            "Epoch:  2\n",
            "207/400.0 loss: 0.6203819580662709 \n",
            "Epoch:  2\n",
            "208/400.0 loss: 0.6207451904504493 \n",
            "Epoch:  2\n",
            "209/400.0 loss: 0.6202934729201454 \n",
            "Epoch:  2\n",
            "210/400.0 loss: 0.6199715336634649 \n",
            "Epoch:  2\n",
            "211/400.0 loss: 0.6201149890164159 \n",
            "Epoch:  2\n",
            "212/400.0 loss: 0.6208916957109747 \n",
            "Epoch:  2\n",
            "213/400.0 loss: 0.621044223971456 \n",
            "Epoch:  2\n",
            "214/400.0 loss: 0.6209500613600709 \n",
            "Epoch:  2\n",
            "215/400.0 loss: 0.6212863305376636 \n",
            "Epoch:  2\n",
            "216/400.0 loss: 0.6207506962910226 \n",
            "Epoch:  2\n",
            "217/400.0 loss: 0.6209380920600454 \n",
            "Epoch:  2\n",
            "218/400.0 loss: 0.6211748108199743 \n",
            "Epoch:  2\n",
            "219/400.0 loss: 0.6208305170590227 \n",
            "Epoch:  2\n",
            "220/400.0 loss: 0.62087850967144 \n",
            "Epoch:  2\n",
            "221/400.0 loss: 0.6211006038629256 \n",
            "Epoch:  2\n",
            "222/400.0 loss: 0.6212693424770116 \n",
            "Epoch:  2\n",
            "223/400.0 loss: 0.6216514125200254 \n",
            "Epoch:  2\n",
            "224/400.0 loss: 0.6206137245231205 \n",
            "Epoch:  2\n",
            "225/400.0 loss: 0.6206468503295848 \n",
            "Epoch:  2\n",
            "226/400.0 loss: 0.6200691436618435 \n",
            "Epoch:  2\n",
            "227/400.0 loss: 0.6195629601154411 \n",
            "Epoch:  2\n",
            "228/400.0 loss: 0.6195593152244018 \n",
            "Epoch:  2\n",
            "229/400.0 loss: 0.6210097125043039 \n",
            "Epoch:  2\n",
            "230/400.0 loss: 0.6209382702519883 \n",
            "Epoch:  2\n",
            "231/400.0 loss: 0.6211370618949676 \n",
            "Epoch:  2\n",
            "232/400.0 loss: 0.6213162312436001 \n",
            "Epoch:  2\n",
            "233/400.0 loss: 0.6216820594337251 \n",
            "Epoch:  2\n",
            "234/400.0 loss: 0.6208798085121399 \n",
            "Epoch:  2\n",
            "235/400.0 loss: 0.6219488636164342 \n",
            "Epoch:  2\n",
            "236/400.0 loss: 0.6222963032591695 \n",
            "Epoch:  2\n",
            "237/400.0 loss: 0.6229061771090291 \n",
            "Epoch:  2\n",
            "238/400.0 loss: 0.6230311222904397 \n",
            "Epoch:  2\n",
            "239/400.0 loss: 0.6222769276549419 \n",
            "Epoch:  2\n",
            "240/400.0 loss: 0.6216544737707035 \n",
            "Epoch:  2\n",
            "241/400.0 loss: 0.6224845513578289 \n",
            "Epoch:  2\n",
            "242/400.0 loss: 0.6226922166936192 \n",
            "Epoch:  2\n",
            "243/400.0 loss: 0.6227616705611104 \n",
            "Epoch:  2\n",
            "244/400.0 loss: 0.6228306238748589 \n",
            "Epoch:  2\n",
            "245/400.0 loss: 0.6227613991595865 \n",
            "Epoch:  2\n",
            "246/400.0 loss: 0.6221350976812695 \n",
            "Epoch:  2\n",
            "247/400.0 loss: 0.622039079906479 \n",
            "Epoch:  2\n",
            "248/400.0 loss: 0.6216252848326441 \n",
            "Epoch:  2\n",
            "249/400.0 loss: 0.6212077882289887 \n",
            "Epoch:  2\n",
            "250/400.0 loss: 0.6216491289822704 \n",
            "Epoch:  2\n",
            "251/400.0 loss: 0.6209955530034171 \n",
            "Epoch:  2\n",
            "252/400.0 loss: 0.6207845213384967 \n",
            "Epoch:  2\n",
            "253/400.0 loss: 0.6202696831676904 \n",
            "Epoch:  2\n",
            "254/400.0 loss: 0.6212662369597192 \n",
            "Epoch:  2\n",
            "255/400.0 loss: 0.6207691663876176 \n",
            "Epoch:  2\n",
            "256/400.0 loss: 0.6202383519146693 \n",
            "Epoch:  2\n",
            "257/400.0 loss: 0.6201372710309287 \n",
            "Epoch:  2\n",
            "258/400.0 loss: 0.6199803313233218 \n",
            "Epoch:  2\n",
            "259/400.0 loss: 0.6211253388569905 \n",
            "Epoch:  2\n",
            "260/400.0 loss: 0.6213875017860383 \n",
            "Epoch:  2\n",
            "261/400.0 loss: 0.6214034418568356 \n",
            "Epoch:  2\n",
            "262/400.0 loss: 0.6203616552706454 \n",
            "Epoch:  2\n",
            "263/400.0 loss: 0.6196085092696276 \n",
            "Epoch:  2\n",
            "264/400.0 loss: 0.6193963905550399 \n",
            "Epoch:  2\n",
            "265/400.0 loss: 0.6198552109693226 \n",
            "Epoch:  2\n",
            "266/400.0 loss: 0.6191122003932125 \n",
            "Epoch:  2\n",
            "267/400.0 loss: 0.6184190699636046 \n",
            "Epoch:  2\n",
            "268/400.0 loss: 0.6183587353690406 \n",
            "Epoch:  2\n",
            "269/400.0 loss: 0.6183564271088 \n",
            "Epoch:  2\n",
            "270/400.0 loss: 0.6175524472530478 \n",
            "Epoch:  2\n",
            "271/400.0 loss: 0.618121837539708 \n",
            "Epoch:  2\n",
            "272/400.0 loss: 0.6184015519671388 \n",
            "Epoch:  2\n",
            "273/400.0 loss: 0.6179127821522038 \n",
            "Epoch:  2\n",
            "274/400.0 loss: 0.6175681939992038 \n",
            "Epoch:  2\n",
            "275/400.0 loss: 0.6175137535817381 \n",
            "Epoch:  2\n",
            "276/400.0 loss: 0.6179509569591564 \n",
            "Epoch:  2\n",
            "277/400.0 loss: 0.6179026828395376 \n",
            "Epoch:  2\n",
            "278/400.0 loss: 0.617815487273705 \n",
            "Epoch:  2\n",
            "279/400.0 loss: 0.6176346127476011 \n",
            "Epoch:  2\n",
            "280/400.0 loss: 0.617702031474945 \n",
            "Epoch:  2\n",
            "281/400.0 loss: 0.6181896058380181 \n",
            "Epoch:  2\n",
            "282/400.0 loss: 0.617972364484632 \n",
            "Epoch:  2\n",
            "283/400.0 loss: 0.6180836915130347 \n",
            "Epoch:  2\n",
            "284/400.0 loss: 0.617432919928902 \n",
            "Epoch:  2\n",
            "285/400.0 loss: 0.6175920848663037 \n",
            "Epoch:  2\n",
            "286/400.0 loss: 0.6167884212545401 \n",
            "Epoch:  2\n",
            "287/400.0 loss: 0.6162447852806913 \n",
            "Epoch:  2\n",
            "288/400.0 loss: 0.6160471957035131 \n",
            "Epoch:  2\n",
            "289/400.0 loss: 0.6164436013534151 \n",
            "Epoch:  2\n",
            "290/400.0 loss: 0.6166706509196881 \n",
            "Epoch:  2\n",
            "291/400.0 loss: 0.6176072361126338 \n",
            "Epoch:  2\n",
            "292/400.0 loss: 0.617619916237255 \n",
            "Epoch:  2\n",
            "293/400.0 loss: 0.6179802154197174 \n",
            "Epoch:  2\n",
            "294/400.0 loss: 0.6182101766941911 \n",
            "Epoch:  2\n",
            "295/400.0 loss: 0.6178742888811473 \n",
            "Epoch:  2\n",
            "296/400.0 loss: 0.6182738321798819 \n",
            "Epoch:  2\n",
            "297/400.0 loss: 0.6185517773132196 \n",
            "Epoch:  2\n",
            "298/400.0 loss: 0.6188506418247287 \n",
            "Epoch:  2\n",
            "299/400.0 loss: 0.6184802440802256 \n",
            "Epoch:  2\n",
            "300/400.0 loss: 0.6180478817600744 \n",
            "Epoch:  2\n",
            "301/400.0 loss: 0.6184749370379163 \n",
            "Epoch:  2\n",
            "302/400.0 loss: 0.619082248053535 \n",
            "Epoch:  2\n",
            "303/400.0 loss: 0.6191223824494764 \n",
            "Epoch:  2\n",
            "304/400.0 loss: 0.6183717784334402 \n",
            "Epoch:  2\n",
            "305/400.0 loss: 0.6180454342583426 \n",
            "Epoch:  2\n",
            "306/400.0 loss: 0.6179627655771733 \n",
            "Epoch:  2\n",
            "307/400.0 loss: 0.6178379614244808 \n",
            "Epoch:  2\n",
            "308/400.0 loss: 0.6173522970051442 \n",
            "Epoch:  2\n",
            "309/400.0 loss: 0.6172407392532595 \n",
            "Epoch:  2\n",
            "310/400.0 loss: 0.6173017866358497 \n",
            "Epoch:  2\n",
            "311/400.0 loss: 0.6166864436788436 \n",
            "Epoch:  2\n",
            "312/400.0 loss: 0.6163593441152725 \n",
            "Epoch:  2\n",
            "313/400.0 loss: 0.6161326853333006 \n",
            "Epoch:  2\n",
            "314/400.0 loss: 0.6158749277629549 \n",
            "Epoch:  2\n",
            "315/400.0 loss: 0.6153593708442736 \n",
            "Epoch:  2\n",
            "316/400.0 loss: 0.6149034882757566 \n",
            "Epoch:  2\n",
            "317/400.0 loss: 0.6167564878486237 \n",
            "Epoch:  2\n",
            "318/400.0 loss: 0.617179337433513 \n",
            "Epoch:  2\n",
            "319/400.0 loss: 0.6165581457316875 \n",
            "Epoch:  2\n",
            "320/400.0 loss: 0.6167926286982599 \n",
            "Epoch:  2\n",
            "321/400.0 loss: 0.6163588231950072 \n",
            "Epoch:  2\n",
            "322/400.0 loss: 0.6164440912174367 \n",
            "Epoch:  2\n",
            "323/400.0 loss: 0.6168907613114074 \n",
            "Epoch:  2\n",
            "324/400.0 loss: 0.6170441555059873 \n",
            "Epoch:  2\n",
            "325/400.0 loss: 0.6171502599869769 \n",
            "Epoch:  2\n",
            "326/400.0 loss: 0.6170649217720791 \n",
            "Epoch:  2\n",
            "327/400.0 loss: 0.6171368908409666 \n",
            "Epoch:  2\n",
            "328/400.0 loss: 0.6170164601237578 \n",
            "Epoch:  2\n",
            "329/400.0 loss: 0.617136671055447 \n",
            "Epoch:  2\n",
            "330/400.0 loss: 0.6168320025021936 \n",
            "Epoch:  2\n",
            "331/400.0 loss: 0.616907425045249 \n",
            "Epoch:  2\n",
            "332/400.0 loss: 0.6174066175032664 \n",
            "Epoch:  2\n",
            "333/400.0 loss: 0.6167126614711955 \n",
            "Epoch:  2\n",
            "334/400.0 loss: 0.6163461691408015 \n",
            "Epoch:  2\n",
            "335/400.0 loss: 0.6157285384833813 \n",
            "Epoch:  2\n",
            "336/400.0 loss: 0.6151633863102435 \n",
            "Epoch:  2\n",
            "337/400.0 loss: 0.6147982190699267 \n",
            "Epoch:  2\n",
            "338/400.0 loss: 0.6144078746657807 \n",
            "Epoch:  2\n",
            "339/400.0 loss: 0.6145636095720179 \n",
            "Epoch:  2\n",
            "340/400.0 loss: 0.6144272505013474 \n",
            "Epoch:  2\n",
            "341/400.0 loss: 0.6139492848288943 \n",
            "Epoch:  2\n",
            "342/400.0 loss: 0.6134206421521246 \n",
            "Epoch:  2\n",
            "343/400.0 loss: 0.6131391965372618 \n",
            "Epoch:  2\n",
            "344/400.0 loss: 0.6126951683258665 \n",
            "Epoch:  2\n",
            "345/400.0 loss: 0.6127986815795733 \n",
            "Epoch:  2\n",
            "346/400.0 loss: 0.6125267016612831 \n",
            "Epoch:  2\n",
            "347/400.0 loss: 0.612459018055735 \n",
            "Epoch:  2\n",
            "348/400.0 loss: 0.6117594892794218 \n",
            "Epoch:  2\n",
            "349/400.0 loss: 0.612497146981103 \n",
            "Epoch:  2\n",
            "350/400.0 loss: 0.6121762148675076 \n",
            "Epoch:  2\n",
            "351/400.0 loss: 0.6112340636212718 \n",
            "Epoch:  2\n",
            "352/400.0 loss: 0.6106493599691742 \n",
            "Epoch:  2\n",
            "353/400.0 loss: 0.6102515467479404 \n",
            "Epoch:  2\n",
            "354/400.0 loss: 0.6107502598158071 \n",
            "Epoch:  2\n",
            "355/400.0 loss: 0.6101025776581818 \n",
            "Epoch:  2\n",
            "356/400.0 loss: 0.6095338342737417 \n",
            "Epoch:  2\n",
            "357/400.0 loss: 0.6096242430656316 \n",
            "Epoch:  2\n",
            "358/400.0 loss: 0.6086155990123084 \n",
            "Epoch:  2\n",
            "359/400.0 loss: 0.6086255184892151 \n",
            "Epoch:  2\n",
            "360/400.0 loss: 0.6086735086840606 \n",
            "Epoch:  2\n",
            "361/400.0 loss: 0.6102448720382063 \n",
            "Epoch:  2\n",
            "362/400.0 loss: 0.60969682908091 \n",
            "Epoch:  2\n",
            "363/400.0 loss: 0.6100512056478432 \n",
            "Epoch:  2\n",
            "364/400.0 loss: 0.6097146687034058 \n",
            "Epoch:  2\n",
            "365/400.0 loss: 0.6109662081618779 \n",
            "Epoch:  2\n",
            "366/400.0 loss: 0.6109153556482668 \n",
            "Epoch:  2\n",
            "367/400.0 loss: 0.6106877467473564 \n",
            "Epoch:  2\n",
            "368/400.0 loss: 0.6106582222188391 \n",
            "Epoch:  2\n",
            "369/400.0 loss: 0.6109304266604217 \n",
            "Epoch:  2\n",
            "370/400.0 loss: 0.6114090320797301 \n",
            "Epoch:  2\n",
            "371/400.0 loss: 0.6110669231462863 \n",
            "Epoch:  2\n",
            "372/400.0 loss: 0.6109752010643962 \n",
            "Epoch:  2\n",
            "373/400.0 loss: 0.6112605120966779 \n",
            "Epoch:  2\n",
            "374/400.0 loss: 0.6107807289361954 \n",
            "Epoch:  2\n",
            "375/400.0 loss: 0.6107007404194867 \n",
            "Epoch:  2\n",
            "376/400.0 loss: 0.6109416057560741 \n",
            "Epoch:  2\n",
            "377/400.0 loss: 0.6112115868421458 \n",
            "Epoch:  2\n",
            "378/400.0 loss: 0.6103780261366223 \n",
            "Epoch:  2\n",
            "379/400.0 loss: 0.6105405109101221 \n",
            "Epoch:  2\n",
            "380/400.0 loss: 0.6100797870262401 \n",
            "Epoch:  2\n",
            "381/400.0 loss: 0.6100377304313694 \n",
            "Epoch:  2\n",
            "382/400.0 loss: 0.6101873862136438 \n",
            "Epoch:  2\n",
            "383/400.0 loss: 0.6103803702862933 \n",
            "Epoch:  2\n",
            "384/400.0 loss: 0.6112011147396905 \n",
            "Epoch:  2\n",
            "385/400.0 loss: 0.6114480621688106 \n",
            "Epoch:  2\n",
            "386/400.0 loss: 0.6115560270942151 \n",
            "Epoch:  2\n",
            "387/400.0 loss: 0.6113608409986668 \n",
            "Epoch:  2\n",
            "388/400.0 loss: 0.6112042177842025 \n",
            "Epoch:  2\n",
            "389/400.0 loss: 0.6111922502135619 \n",
            "Epoch:  2\n",
            "390/400.0 loss: 0.6113342709477295 \n",
            "Epoch:  2\n",
            "391/400.0 loss: 0.6111941419313757 \n",
            "Epoch:  2\n",
            "392/400.0 loss: 0.6111788852448379 \n",
            "Epoch:  2\n",
            "393/400.0 loss: 0.6111137787929646 \n",
            "Epoch:  2\n",
            "394/400.0 loss: 0.6111117000444026 \n",
            "Epoch:  2\n",
            "395/400.0 loss: 0.6114037463987114 \n",
            "Epoch:  2\n",
            "396/400.0 loss: 0.6113854014227913 \n",
            "Epoch:  2\n",
            "397/400.0 loss: 0.6117170373324173 \n",
            "Epoch:  2\n",
            "398/400.0 loss: 0.6118791132866589 \n",
            "Epoch:  2\n",
            "399/400.0 loss: 0.6115890709683299 \n",
            "Epoch:  3\n",
            "0/400.0 loss: 0.5825880765914917 \n",
            "Epoch:  3\n",
            "1/400.0 loss: 0.5949744880199432 \n",
            "Epoch:  3\n",
            "2/400.0 loss: 0.59055628379186 \n",
            "Epoch:  3\n",
            "3/400.0 loss: 0.6145262271165848 \n",
            "Epoch:  3\n",
            "4/400.0 loss: 0.622419559955597 \n",
            "Epoch:  3\n",
            "5/400.0 loss: 0.6146450738112131 \n",
            "Epoch:  3\n",
            "6/400.0 loss: 0.5914131360394614 \n",
            "Epoch:  3\n",
            "7/400.0 loss: 0.5828436650335789 \n",
            "Epoch:  3\n",
            "8/400.0 loss: 0.5667160848776499 \n",
            "Epoch:  3\n",
            "9/400.0 loss: 0.5636662393808365 \n",
            "Epoch:  3\n",
            "10/400.0 loss: 0.5525638244368813 \n",
            "Epoch:  3\n",
            "11/400.0 loss: 0.5528939515352249 \n",
            "Epoch:  3\n",
            "12/400.0 loss: 0.537260495699369 \n",
            "Epoch:  3\n",
            "13/400.0 loss: 0.5313262343406677 \n",
            "Epoch:  3\n",
            "14/400.0 loss: 0.5308486302693685 \n",
            "Epoch:  3\n",
            "15/400.0 loss: 0.5219189375638962 \n",
            "Epoch:  3\n",
            "16/400.0 loss: 0.5254015922546387 \n",
            "Epoch:  3\n",
            "17/400.0 loss: 0.5176358769337336 \n",
            "Epoch:  3\n",
            "18/400.0 loss: 0.5253230913689262 \n",
            "Epoch:  3\n",
            "19/400.0 loss: 0.5155911862850189 \n",
            "Epoch:  3\n",
            "20/400.0 loss: 0.4986989207210995 \n",
            "Epoch:  3\n",
            "21/400.0 loss: 0.5004346038807522 \n",
            "Epoch:  3\n",
            "22/400.0 loss: 0.5092303331779398 \n",
            "Epoch:  3\n",
            "23/400.0 loss: 0.5302639100700617 \n",
            "Epoch:  3\n",
            "24/400.0 loss: 0.5204546493291855 \n",
            "Epoch:  3\n",
            "25/400.0 loss: 0.52155285099378 \n",
            "Epoch:  3\n",
            "26/400.0 loss: 0.521927316431646 \n",
            "Epoch:  3\n",
            "27/400.0 loss: 0.51400814684374 \n",
            "Epoch:  3\n",
            "28/400.0 loss: 0.5148497814762181 \n",
            "Epoch:  3\n",
            "29/400.0 loss: 0.5095075185100237 \n",
            "Epoch:  3\n",
            "30/400.0 loss: 0.5329355631143816 \n",
            "Epoch:  3\n",
            "31/400.0 loss: 0.5393573748879135 \n",
            "Epoch:  3\n",
            "32/400.0 loss: 0.5360719719619462 \n",
            "Epoch:  3\n",
            "33/400.0 loss: 0.5408959542127216 \n",
            "Epoch:  3\n",
            "34/400.0 loss: 0.5429849722555705 \n",
            "Epoch:  3\n",
            "35/400.0 loss: 0.5398738082084391 \n",
            "Epoch:  3\n",
            "36/400.0 loss: 0.5387662878713092 \n",
            "Epoch:  3\n",
            "37/400.0 loss: 0.5357388920689884 \n",
            "Epoch:  3\n",
            "38/400.0 loss: 0.549391236442786 \n",
            "Epoch:  3\n",
            "39/400.0 loss: 0.5498374316841363 \n",
            "Epoch:  3\n",
            "40/400.0 loss: 0.5522901448534756 \n",
            "Epoch:  3\n",
            "41/400.0 loss: 0.5486332877051263 \n",
            "Epoch:  3\n",
            "42/400.0 loss: 0.5532163093949474 \n",
            "Epoch:  3\n",
            "43/400.0 loss: 0.5505246272818609 \n",
            "Epoch:  3\n",
            "44/400.0 loss: 0.5522320850027932 \n",
            "Epoch:  3\n",
            "45/400.0 loss: 0.5532633840389873 \n",
            "Epoch:  3\n",
            "46/400.0 loss: 0.5552710760781105 \n",
            "Epoch:  3\n",
            "47/400.0 loss: 0.5524624365692338 \n",
            "Epoch:  3\n",
            "48/400.0 loss: 0.5510459289867051 \n",
            "Epoch:  3\n",
            "49/400.0 loss: 0.5547864678502082 \n",
            "Epoch:  3\n",
            "50/400.0 loss: 0.5519227008609211 \n",
            "Epoch:  3\n",
            "51/400.0 loss: 0.5513221412323989 \n",
            "Epoch:  3\n",
            "52/400.0 loss: 0.5483519060994094 \n",
            "Epoch:  3\n",
            "53/400.0 loss: 0.5541012372683596 \n",
            "Epoch:  3\n",
            "54/400.0 loss: 0.5514247886159204 \n",
            "Epoch:  3\n",
            "55/400.0 loss: 0.5480098146945238 \n",
            "Epoch:  3\n",
            "56/400.0 loss: 0.5487582450895979 \n",
            "Epoch:  3\n",
            "57/400.0 loss: 0.5444732675778454 \n",
            "Epoch:  3\n",
            "58/400.0 loss: 0.5449178044573736 \n",
            "Epoch:  3\n",
            "59/400.0 loss: 0.5452519563337167 \n",
            "Epoch:  3\n",
            "60/400.0 loss: 0.5420163838101215 \n",
            "Epoch:  3\n",
            "61/400.0 loss: 0.5439364878881362 \n",
            "Epoch:  3\n",
            "62/400.0 loss: 0.5425439578673196 \n",
            "Epoch:  3\n",
            "63/400.0 loss: 0.5425886826124042 \n",
            "Epoch:  3\n",
            "64/400.0 loss: 0.5403255125650993 \n",
            "Epoch:  3\n",
            "65/400.0 loss: 0.5445079760569514 \n",
            "Epoch:  3\n",
            "66/400.0 loss: 0.5425703340946738 \n",
            "Epoch:  3\n",
            "67/400.0 loss: 0.5435503153678249 \n",
            "Epoch:  3\n",
            "68/400.0 loss: 0.5460767696301142 \n",
            "Epoch:  3\n",
            "69/400.0 loss: 0.5438891404441425 \n",
            "Epoch:  3\n",
            "70/400.0 loss: 0.544934362802707 \n",
            "Epoch:  3\n",
            "71/400.0 loss: 0.547967236282097 \n",
            "Epoch:  3\n",
            "72/400.0 loss: 0.5465941247466493 \n",
            "Epoch:  3\n",
            "73/400.0 loss: 0.5460101943966504 \n",
            "Epoch:  3\n",
            "74/400.0 loss: 0.5447826085488001 \n",
            "Epoch:  3\n",
            "75/400.0 loss: 0.5419711598048085 \n",
            "Epoch:  3\n",
            "76/400.0 loss: 0.542520008497424 \n",
            "Epoch:  3\n",
            "77/400.0 loss: 0.5470186557907325 \n",
            "Epoch:  3\n",
            "78/400.0 loss: 0.5495119828589355 \n",
            "Epoch:  3\n",
            "79/400.0 loss: 0.5492024743929506 \n",
            "Epoch:  3\n",
            "80/400.0 loss: 0.5570067750451005 \n",
            "Epoch:  3\n",
            "81/400.0 loss: 0.556641132548088 \n",
            "Epoch:  3\n",
            "82/400.0 loss: 0.5580047349254769 \n",
            "Epoch:  3\n",
            "83/400.0 loss: 0.5579666915748801 \n",
            "Epoch:  3\n",
            "84/400.0 loss: 0.5595772541621152 \n",
            "Epoch:  3\n",
            "85/400.0 loss: 0.5609893343129824 \n",
            "Epoch:  3\n",
            "86/400.0 loss: 0.5600979292187197 \n",
            "Epoch:  3\n",
            "87/400.0 loss: 0.5585878838530995 \n",
            "Epoch:  3\n",
            "88/400.0 loss: 0.5577088137356083 \n",
            "Epoch:  3\n",
            "89/400.0 loss: 0.5561120770043797 \n",
            "Epoch:  3\n",
            "90/400.0 loss: 0.5569430820562027 \n",
            "Epoch:  3\n",
            "91/400.0 loss: 0.5554158225979494 \n",
            "Epoch:  3\n",
            "92/400.0 loss: 0.5542127514077771 \n",
            "Epoch:  3\n",
            "93/400.0 loss: 0.5523090297554402 \n",
            "Epoch:  3\n",
            "94/400.0 loss: 0.5547597933756677 \n",
            "Epoch:  3\n",
            "95/400.0 loss: 0.5541288205422461 \n",
            "Epoch:  3\n",
            "96/400.0 loss: 0.5534056552599386 \n",
            "Epoch:  3\n",
            "97/400.0 loss: 0.5530537699862402 \n",
            "Epoch:  3\n",
            "98/400.0 loss: 0.5493470722376698 \n",
            "Epoch:  3\n",
            "99/400.0 loss: 0.5478417691588402 \n",
            "Epoch:  3\n",
            "100/400.0 loss: 0.5483347127343169 \n",
            "Epoch:  3\n",
            "101/400.0 loss: 0.5472582534832113 \n",
            "Epoch:  3\n",
            "102/400.0 loss: 0.5495959760494602 \n",
            "Epoch:  3\n",
            "103/400.0 loss: 0.5492475161758753 \n",
            "Epoch:  3\n",
            "104/400.0 loss: 0.5482206086317698 \n",
            "Epoch:  3\n",
            "105/400.0 loss: 0.5497306593746509 \n",
            "Epoch:  3\n",
            "106/400.0 loss: 0.5483971697704815 \n",
            "Epoch:  3\n",
            "107/400.0 loss: 0.54754655311505 \n",
            "Epoch:  3\n",
            "108/400.0 loss: 0.5446841705829726 \n",
            "Epoch:  3\n",
            "109/400.0 loss: 0.5448195620016618 \n",
            "Epoch:  3\n",
            "110/400.0 loss: 0.5437713007669192 \n",
            "Epoch:  3\n",
            "111/400.0 loss: 0.5410905936732888 \n",
            "Epoch:  3\n",
            "112/400.0 loss: 0.5400745091976318 \n",
            "Epoch:  3\n",
            "113/400.0 loss: 0.5462330165400839 \n",
            "Epoch:  3\n",
            "114/400.0 loss: 0.5480413534071135 \n",
            "Epoch:  3\n",
            "115/400.0 loss: 0.5503744327559553 \n",
            "Epoch:  3\n",
            "116/400.0 loss: 0.5496301713407549 \n",
            "Epoch:  3\n",
            "117/400.0 loss: 0.5470707109671528 \n",
            "Epoch:  3\n",
            "118/400.0 loss: 0.549925223744216 \n",
            "Epoch:  3\n",
            "119/400.0 loss: 0.5539961076031129 \n",
            "Epoch:  3\n",
            "120/400.0 loss: 0.5506579707230418 \n",
            "Epoch:  3\n",
            "121/400.0 loss: 0.5491254709538866 \n",
            "Epoch:  3\n",
            "122/400.0 loss: 0.5488475298251563 \n",
            "Epoch:  3\n",
            "123/400.0 loss: 0.5492042720077499 \n",
            "Epoch:  3\n",
            "124/400.0 loss: 0.5481058386564255 \n",
            "Epoch:  3\n",
            "125/400.0 loss: 0.5492871624846307 \n",
            "Epoch:  3\n",
            "126/400.0 loss: 0.5504283176397714 \n",
            "Epoch:  3\n",
            "127/400.0 loss: 0.5510988616151735 \n",
            "Epoch:  3\n",
            "128/400.0 loss: 0.5522682508525922 \n",
            "Epoch:  3\n",
            "129/400.0 loss: 0.5524770588828967 \n",
            "Epoch:  3\n",
            "130/400.0 loss: 0.5525359733186606 \n",
            "Epoch:  3\n",
            "131/400.0 loss: 0.5502736048039162 \n",
            "Epoch:  3\n",
            "132/400.0 loss: 0.549936758284282 \n",
            "Epoch:  3\n",
            "133/400.0 loss: 0.5508091052743926 \n",
            "Epoch:  3\n",
            "134/400.0 loss: 0.5503188282251358 \n",
            "Epoch:  3\n",
            "135/400.0 loss: 0.5490264071918586 \n",
            "Epoch:  3\n",
            "136/400.0 loss: 0.5486951904357785 \n",
            "Epoch:  3\n",
            "137/400.0 loss: 0.548376698748789 \n",
            "Epoch:  3\n",
            "138/400.0 loss: 0.5464650537255856 \n",
            "Epoch:  3\n",
            "139/400.0 loss: 0.5465414212218352 \n",
            "Epoch:  3\n",
            "140/400.0 loss: 0.5464795970536293 \n",
            "Epoch:  3\n",
            "141/400.0 loss: 0.545115979729404 \n",
            "Epoch:  3\n",
            "142/400.0 loss: 0.5439994323712128 \n",
            "Epoch:  3\n",
            "143/400.0 loss: 0.542766177923315 \n",
            "Epoch:  3\n",
            "144/400.0 loss: 0.5429202023251304 \n",
            "Epoch:  3\n",
            "145/400.0 loss: 0.5418580616377804 \n",
            "Epoch:  3\n",
            "146/400.0 loss: 0.5431264072251157 \n",
            "Epoch:  3\n",
            "147/400.0 loss: 0.5411855533114962 \n",
            "Epoch:  3\n",
            "148/400.0 loss: 0.5408020870597571 \n",
            "Epoch:  3\n",
            "149/400.0 loss: 0.5401417163014411 \n",
            "Epoch:  3\n",
            "150/400.0 loss: 0.5394022554553897 \n",
            "Epoch:  3\n",
            "151/400.0 loss: 0.5419839921554452 \n",
            "Epoch:  3\n",
            "152/400.0 loss: 0.5414740407194187 \n",
            "Epoch:  3\n",
            "153/400.0 loss: 0.5424582388300401 \n",
            "Epoch:  3\n",
            "154/400.0 loss: 0.5429902168050889 \n",
            "Epoch:  3\n",
            "155/400.0 loss: 0.5407400499933805 \n",
            "Epoch:  3\n",
            "156/400.0 loss: 0.5418630156927048 \n",
            "Epoch:  3\n",
            "157/400.0 loss: 0.5414374883793578 \n",
            "Epoch:  3\n",
            "158/400.0 loss: 0.541364867544774 \n",
            "Epoch:  3\n",
            "159/400.0 loss: 0.5417672922834754 \n",
            "Epoch:  3\n",
            "160/400.0 loss: 0.5416760953686992 \n",
            "Epoch:  3\n",
            "161/400.0 loss: 0.5439734957468363 \n",
            "Epoch:  3\n",
            "162/400.0 loss: 0.5432198170138283 \n",
            "Epoch:  3\n",
            "163/400.0 loss: 0.5430069189609551 \n",
            "Epoch:  3\n",
            "164/400.0 loss: 0.5426603499687079 \n",
            "Epoch:  3\n",
            "165/400.0 loss: 0.5415061128785811 \n",
            "Epoch:  3\n",
            "166/400.0 loss: 0.5447563159608555 \n",
            "Epoch:  3\n",
            "167/400.0 loss: 0.5439703370488825 \n",
            "Epoch:  3\n",
            "168/400.0 loss: 0.544422943034821 \n",
            "Epoch:  3\n",
            "169/400.0 loss: 0.54386027367676 \n",
            "Epoch:  3\n",
            "170/400.0 loss: 0.5429482629076082 \n",
            "Epoch:  3\n",
            "171/400.0 loss: 0.5419758102575014 \n",
            "Epoch:  3\n",
            "172/400.0 loss: 0.5410822333628043 \n",
            "Epoch:  3\n",
            "173/400.0 loss: 0.5397408070235417 \n",
            "Epoch:  3\n",
            "174/400.0 loss: 0.5406177112034389 \n",
            "Epoch:  3\n",
            "175/400.0 loss: 0.5405000847848979 \n",
            "Epoch:  3\n",
            "176/400.0 loss: 0.5407500357951148 \n",
            "Epoch:  3\n",
            "177/400.0 loss: 0.539050411558553 \n",
            "Epoch:  3\n",
            "178/400.0 loss: 0.5385272062524071 \n",
            "Epoch:  3\n",
            "179/400.0 loss: 0.5385726798739698 \n",
            "Epoch:  3\n",
            "180/400.0 loss: 0.5379972139280804 \n",
            "Epoch:  3\n",
            "181/400.0 loss: 0.5371388924809603 \n",
            "Epoch:  3\n",
            "182/400.0 loss: 0.5381455197523201 \n",
            "Epoch:  3\n",
            "183/400.0 loss: 0.5376879393892444 \n",
            "Epoch:  3\n",
            "184/400.0 loss: 0.5380252956538587 \n",
            "Epoch:  3\n",
            "185/400.0 loss: 0.5380480048316781 \n",
            "Epoch:  3\n",
            "186/400.0 loss: 0.5378263878790452 \n",
            "Epoch:  3\n",
            "187/400.0 loss: 0.5389450359693233 \n",
            "Epoch:  3\n",
            "188/400.0 loss: 0.5384718022806935 \n",
            "Epoch:  3\n",
            "189/400.0 loss: 0.538085206637257 \n",
            "Epoch:  3\n",
            "190/400.0 loss: 0.538696727905598 \n",
            "Epoch:  3\n",
            "191/400.0 loss: 0.5391351910463223 \n",
            "Epoch:  3\n",
            "192/400.0 loss: 0.5393279522966227 \n",
            "Epoch:  3\n",
            "193/400.0 loss: 0.5384874098847822 \n",
            "Epoch:  3\n",
            "194/400.0 loss: 0.5391375686113651 \n",
            "Epoch:  3\n",
            "195/400.0 loss: 0.5383807634364586 \n",
            "Epoch:  3\n",
            "196/400.0 loss: 0.5396053368216238 \n",
            "Epoch:  3\n",
            "197/400.0 loss: 0.5389844312360792 \n",
            "Epoch:  3\n",
            "198/400.0 loss: 0.5392513230967162 \n",
            "Epoch:  3\n",
            "199/400.0 loss: 0.5379999632388354 \n",
            "Epoch:  3\n",
            "200/400.0 loss: 0.5390821414355614 \n",
            "Epoch:  3\n",
            "201/400.0 loss: 0.5399396511735303 \n",
            "Epoch:  3\n",
            "202/400.0 loss: 0.5400034950431345 \n",
            "Epoch:  3\n",
            "203/400.0 loss: 0.5399046245889336 \n",
            "Epoch:  3\n",
            "204/400.0 loss: 0.5408194789799249 \n",
            "Epoch:  3\n",
            "205/400.0 loss: 0.5401899954213679 \n",
            "Epoch:  3\n",
            "206/400.0 loss: 0.541466251735526 \n",
            "Epoch:  3\n",
            "207/400.0 loss: 0.5423979696889336 \n",
            "Epoch:  3\n",
            "208/400.0 loss: 0.5417960534968445 \n",
            "Epoch:  3\n",
            "209/400.0 loss: 0.5422032141259738 \n",
            "Epoch:  3\n",
            "210/400.0 loss: 0.5413537500735143 \n",
            "Epoch:  3\n",
            "211/400.0 loss: 0.5411406832061848 \n",
            "Epoch:  3\n",
            "212/400.0 loss: 0.5405370537803766 \n",
            "Epoch:  3\n",
            "213/400.0 loss: 0.5401633803114713 \n",
            "Epoch:  3\n",
            "214/400.0 loss: 0.5393991010826688 \n",
            "Epoch:  3\n",
            "215/400.0 loss: 0.5416388341260178 \n",
            "Epoch:  3\n",
            "216/400.0 loss: 0.5415759845400736 \n",
            "Epoch:  3\n",
            "217/400.0 loss: 0.5420358162544189 \n",
            "Epoch:  3\n",
            "218/400.0 loss: 0.5418315855743678 \n",
            "Epoch:  3\n",
            "219/400.0 loss: 0.5412671825425192 \n",
            "Epoch:  3\n",
            "220/400.0 loss: 0.541091099516299 \n",
            "Epoch:  3\n",
            "221/400.0 loss: 0.5408320010111138 \n",
            "Epoch:  3\n",
            "222/400.0 loss: 0.5402624796190604 \n",
            "Epoch:  3\n",
            "223/400.0 loss: 0.5405787513591349 \n",
            "Epoch:  3\n",
            "224/400.0 loss: 0.5418394194046656 \n",
            "Epoch:  3\n",
            "225/400.0 loss: 0.5424312969620249 \n",
            "Epoch:  3\n",
            "226/400.0 loss: 0.5422090605098245 \n",
            "Epoch:  3\n",
            "227/400.0 loss: 0.5416890987309447 \n",
            "Epoch:  3\n",
            "228/400.0 loss: 0.5409502809354833 \n",
            "Epoch:  3\n",
            "229/400.0 loss: 0.5396313908955325 \n",
            "Epoch:  3\n",
            "230/400.0 loss: 0.5388396673259281 \n",
            "Epoch:  3\n",
            "231/400.0 loss: 0.5387710833215508 \n",
            "Epoch:  3\n",
            "232/400.0 loss: 0.5378876468526447 \n",
            "Epoch:  3\n",
            "233/400.0 loss: 0.5370764065629396 \n",
            "Epoch:  3\n",
            "234/400.0 loss: 0.5352637423796857 \n",
            "Epoch:  3\n",
            "235/400.0 loss: 0.5350850207762698 \n",
            "Epoch:  3\n",
            "236/400.0 loss: 0.5347692016747934 \n",
            "Epoch:  3\n",
            "237/400.0 loss: 0.5346573181450367 \n",
            "Epoch:  3\n",
            "238/400.0 loss: 0.5335895149465885 \n",
            "Epoch:  3\n",
            "239/400.0 loss: 0.5338705929306646 \n",
            "Epoch:  3\n",
            "240/400.0 loss: 0.5335624717268707 \n",
            "Epoch:  3\n",
            "241/400.0 loss: 0.5340769849717617 \n",
            "Epoch:  3\n",
            "242/400.0 loss: 0.5339504188164271 \n",
            "Epoch:  3\n",
            "243/400.0 loss: 0.5343163408888657 \n",
            "Epoch:  3\n",
            "244/400.0 loss: 0.5333508374435562 \n",
            "Epoch:  3\n",
            "245/400.0 loss: 0.5317323715161018 \n",
            "Epoch:  3\n",
            "246/400.0 loss: 0.5315168383814063 \n",
            "Epoch:  3\n",
            "247/400.0 loss: 0.5303851268404434 \n",
            "Epoch:  3\n",
            "248/400.0 loss: 0.5297687460320541 \n",
            "Epoch:  3\n",
            "249/400.0 loss: 0.5307454592883587 \n",
            "Epoch:  3\n",
            "250/400.0 loss: 0.5304116644410498 \n",
            "Epoch:  3\n",
            "251/400.0 loss: 0.5301534788653491 \n",
            "Epoch:  3\n",
            "252/400.0 loss: 0.5292582833189738 \n",
            "Epoch:  3\n",
            "253/400.0 loss: 0.5281324449075958 \n",
            "Epoch:  3\n",
            "254/400.0 loss: 0.5273011446291325 \n",
            "Epoch:  3\n",
            "255/400.0 loss: 0.5269545450864825 \n",
            "Epoch:  3\n",
            "256/400.0 loss: 0.5267194066819978 \n",
            "Epoch:  3\n",
            "257/400.0 loss: 0.5255057275468527 \n",
            "Epoch:  3\n",
            "258/400.0 loss: 0.5244122638608038 \n",
            "Epoch:  3\n",
            "259/400.0 loss: 0.5243113585103016 \n",
            "Epoch:  3\n",
            "260/400.0 loss: 0.5275114846355157 \n",
            "Epoch:  3\n",
            "261/400.0 loss: 0.528931011993239 \n",
            "Epoch:  3\n",
            "262/400.0 loss: 0.529676844723551 \n",
            "Epoch:  3\n",
            "263/400.0 loss: 0.5296615945513953 \n",
            "Epoch:  3\n",
            "264/400.0 loss: 0.531013980535966 \n",
            "Epoch:  3\n",
            "265/400.0 loss: 0.5315020266724261 \n",
            "Epoch:  3\n",
            "266/400.0 loss: 0.5332245048456424 \n",
            "Epoch:  3\n",
            "267/400.0 loss: 0.534617495486763 \n",
            "Epoch:  3\n",
            "268/400.0 loss: 0.5348117463152204 \n",
            "Epoch:  3\n",
            "269/400.0 loss: 0.5353593849197582 \n",
            "Epoch:  3\n",
            "270/400.0 loss: 0.5350645363495798 \n",
            "Epoch:  3\n",
            "271/400.0 loss: 0.5345165825668065 \n",
            "Epoch:  3\n",
            "272/400.0 loss: 0.5353744488223132 \n",
            "Epoch:  3\n",
            "273/400.0 loss: 0.5360345315922351 \n",
            "Epoch:  3\n",
            "274/400.0 loss: 0.5357064845074306 \n",
            "Epoch:  3\n",
            "275/400.0 loss: 0.5354447980019925 \n",
            "Epoch:  3\n",
            "276/400.0 loss: 0.5353698172885588 \n",
            "Epoch:  3\n",
            "277/400.0 loss: 0.5361542169728296 \n",
            "Epoch:  3\n",
            "278/400.0 loss: 0.5359187074619809 \n",
            "Epoch:  3\n",
            "279/400.0 loss: 0.5359807320737413 \n",
            "Epoch:  3\n",
            "280/400.0 loss: 0.53614794420496 \n",
            "Epoch:  3\n",
            "281/400.0 loss: 0.5360077256799167 \n",
            "Epoch:  3\n",
            "282/400.0 loss: 0.5359587352130523 \n",
            "Epoch:  3\n",
            "283/400.0 loss: 0.5367577267731999 \n",
            "Epoch:  3\n",
            "284/400.0 loss: 0.5360608347413832 \n",
            "Epoch:  3\n",
            "285/400.0 loss: 0.5360648335849906 \n",
            "Epoch:  3\n",
            "286/400.0 loss: 0.5355897721045939 \n",
            "Epoch:  3\n",
            "287/400.0 loss: 0.5350565225041161 \n",
            "Epoch:  3\n",
            "288/400.0 loss: 0.5347202628283765 \n",
            "Epoch:  3\n",
            "289/400.0 loss: 0.5352330115077825 \n",
            "Epoch:  3\n",
            "290/400.0 loss: 0.5346345518206813 \n",
            "Epoch:  3\n",
            "291/400.0 loss: 0.5338777046242397 \n",
            "Epoch:  3\n",
            "292/400.0 loss: 0.5333973818010438 \n",
            "Epoch:  3\n",
            "293/400.0 loss: 0.5347042973501747 \n",
            "Epoch:  3\n",
            "294/400.0 loss: 0.5347455268946745 \n",
            "Epoch:  3\n",
            "295/400.0 loss: 0.535727783206951 \n",
            "Epoch:  3\n",
            "296/400.0 loss: 0.5362541721475245 \n",
            "Epoch:  3\n",
            "297/400.0 loss: 0.5375867559755808 \n",
            "Epoch:  3\n",
            "298/400.0 loss: 0.5370801940161648 \n",
            "Epoch:  3\n",
            "299/400.0 loss: 0.5365403898308675 \n",
            "Epoch:  3\n",
            "300/400.0 loss: 0.535811551459802 \n",
            "Epoch:  3\n",
            "301/400.0 loss: 0.5349910138606631 \n",
            "Epoch:  3\n",
            "302/400.0 loss: 0.5355924656829818 \n",
            "Epoch:  3\n",
            "303/400.0 loss: 0.5357076915618229 \n",
            "Epoch:  3\n",
            "304/400.0 loss: 0.5364711438778971 \n",
            "Epoch:  3\n",
            "305/400.0 loss: 0.5360563630907754 \n",
            "Epoch:  3\n",
            "306/400.0 loss: 0.5363419467298138 \n",
            "Epoch:  3\n",
            "307/400.0 loss: 0.5362986612387679 \n",
            "Epoch:  3\n",
            "308/400.0 loss: 0.5353496505556369 \n",
            "Epoch:  3\n",
            "309/400.0 loss: 0.5363822043663071 \n",
            "Epoch:  3\n",
            "310/400.0 loss: 0.5361540247341827 \n",
            "Epoch:  3\n",
            "311/400.0 loss: 0.5355986943946053 \n",
            "Epoch:  3\n",
            "312/400.0 loss: 0.5350000944714577 \n",
            "Epoch:  3\n",
            "313/400.0 loss: 0.5354895180530229 \n",
            "Epoch:  3\n",
            "314/400.0 loss: 0.5365730895646035 \n",
            "Epoch:  3\n",
            "315/400.0 loss: 0.5362223677007081 \n",
            "Epoch:  3\n",
            "316/400.0 loss: 0.5366813115282013 \n",
            "Epoch:  3\n",
            "317/400.0 loss: 0.5368322201260606 \n",
            "Epoch:  3\n",
            "318/400.0 loss: 0.5369138803368078 \n",
            "Epoch:  3\n",
            "319/400.0 loss: 0.5368278924142942 \n",
            "Epoch:  3\n",
            "320/400.0 loss: 0.5371484808229212 \n",
            "Epoch:  3\n",
            "321/400.0 loss: 0.5369629058177057 \n",
            "Epoch:  3\n",
            "322/400.0 loss: 0.5370646021083781 \n",
            "Epoch:  3\n",
            "323/400.0 loss: 0.5367457629123955 \n",
            "Epoch:  3\n",
            "324/400.0 loss: 0.5372180989843148 \n",
            "Epoch:  3\n",
            "325/400.0 loss: 0.5363142292238087 \n",
            "Epoch:  3\n",
            "326/400.0 loss: 0.5361526593201387 \n",
            "Epoch:  3\n",
            "327/400.0 loss: 0.5363288624666449 \n",
            "Epoch:  3\n",
            "328/400.0 loss: 0.5363151372430173 \n",
            "Epoch:  3\n",
            "329/400.0 loss: 0.536465896011302 \n",
            "Epoch:  3\n",
            "330/400.0 loss: 0.5364910329261575 \n",
            "Epoch:  3\n",
            "331/400.0 loss: 0.5363040409578257 \n",
            "Epoch:  3\n",
            "332/400.0 loss: 0.5358127933051493 \n",
            "Epoch:  3\n",
            "333/400.0 loss: 0.5352214033419858 \n",
            "Epoch:  3\n",
            "334/400.0 loss: 0.5353432305935604 \n",
            "Epoch:  3\n",
            "335/400.0 loss: 0.5365060992938068 \n",
            "Epoch:  3\n",
            "336/400.0 loss: 0.5363678835133416 \n",
            "Epoch:  3\n",
            "337/400.0 loss: 0.5358263429849458 \n",
            "Epoch:  3\n",
            "338/400.0 loss: 0.5350785173893327 \n",
            "Epoch:  3\n",
            "339/400.0 loss: 0.5344758350402117 \n",
            "Epoch:  3\n",
            "340/400.0 loss: 0.5344674345379001 \n",
            "Epoch:  3\n",
            "341/400.0 loss: 0.5340279763597146 \n",
            "Epoch:  3\n",
            "342/400.0 loss: 0.5333991825102717 \n",
            "Epoch:  3\n",
            "343/400.0 loss: 0.5329416510540732 \n",
            "Epoch:  3\n",
            "344/400.0 loss: 0.5329486679555713 \n",
            "Epoch:  3\n",
            "345/400.0 loss: 0.5318555543145348 \n",
            "Epoch:  3\n",
            "346/400.0 loss: 0.5318857751550523 \n",
            "Epoch:  3\n",
            "347/400.0 loss: 0.5322744514707519 \n",
            "Epoch:  3\n",
            "348/400.0 loss: 0.5323943036973989 \n",
            "Epoch:  3\n",
            "349/400.0 loss: 0.5319873525202274 \n",
            "Epoch:  3\n",
            "350/400.0 loss: 0.5321666723769954 \n",
            "Epoch:  3\n",
            "351/400.0 loss: 0.5318182316312398 \n",
            "Epoch:  3\n",
            "352/400.0 loss: 0.5321850046177762 \n",
            "Epoch:  3\n",
            "353/400.0 loss: 0.5310295114746202 \n",
            "Epoch:  3\n",
            "354/400.0 loss: 0.5319430371405374 \n",
            "Epoch:  3\n",
            "355/400.0 loss: 0.53182819535893 \n",
            "Epoch:  3\n",
            "356/400.0 loss: 0.5322004575021461 \n",
            "Epoch:  3\n",
            "357/400.0 loss: 0.5318901878495456 \n",
            "Epoch:  3\n",
            "358/400.0 loss: 0.5323891925280473 \n",
            "Epoch:  3\n",
            "359/400.0 loss: 0.5315712504916721 \n",
            "Epoch:  3\n",
            "360/400.0 loss: 0.5309815476145441 \n",
            "Epoch:  3\n",
            "361/400.0 loss: 0.5315787438200323 \n",
            "Epoch:  3\n",
            "362/400.0 loss: 0.5321683573328759 \n",
            "Epoch:  3\n",
            "363/400.0 loss: 0.5320620883952131 \n",
            "Epoch:  3\n",
            "364/400.0 loss: 0.5314060960730461 \n",
            "Epoch:  3\n",
            "365/400.0 loss: 0.5304836698405729 \n",
            "Epoch:  3\n",
            "366/400.0 loss: 0.5306654838028007 \n",
            "Epoch:  3\n",
            "367/400.0 loss: 0.5309377387975869 \n",
            "Epoch:  3\n",
            "368/400.0 loss: 0.5305960739692699 \n",
            "Epoch:  3\n",
            "369/400.0 loss: 0.5310340021913116 \n",
            "Epoch:  3\n",
            "370/400.0 loss: 0.5320026072048434 \n",
            "Epoch:  3\n",
            "371/400.0 loss: 0.5323262180211723 \n",
            "Epoch:  3\n",
            "372/400.0 loss: 0.5322212222913635 \n",
            "Epoch:  3\n",
            "373/400.0 loss: 0.5318420452070746 \n",
            "Epoch:  3\n",
            "374/400.0 loss: 0.5312760042349497 \n",
            "Epoch:  3\n",
            "375/400.0 loss: 0.5315906834253605 \n",
            "Epoch:  3\n",
            "376/400.0 loss: 0.5315342209541513 \n",
            "Epoch:  3\n",
            "377/400.0 loss: 0.5326251552376167 \n",
            "Epoch:  3\n",
            "378/400.0 loss: 0.5339886353481413 \n",
            "Epoch:  3\n",
            "379/400.0 loss: 0.5337003350257874 \n",
            "Epoch:  3\n",
            "380/400.0 loss: 0.5349193603347918 \n",
            "Epoch:  3\n",
            "381/400.0 loss: 0.5348637994983434 \n",
            "Epoch:  3\n",
            "382/400.0 loss: 0.5345475438680724 \n",
            "Epoch:  3\n",
            "383/400.0 loss: 0.5349267014923195 \n",
            "Epoch:  3\n",
            "384/400.0 loss: 0.535008813963308 \n",
            "Epoch:  3\n",
            "385/400.0 loss: 0.5349503914618121 \n",
            "Epoch:  3\n",
            "386/400.0 loss: 0.5353907332863919 \n",
            "Epoch:  3\n",
            "387/400.0 loss: 0.53515753664614 \n",
            "Epoch:  3\n",
            "388/400.0 loss: 0.5345793034699399 \n",
            "Epoch:  3\n",
            "389/400.0 loss: 0.5348870886441989 \n",
            "Epoch:  3\n",
            "390/400.0 loss: 0.5349954381165907 \n",
            "Epoch:  3\n",
            "391/400.0 loss: 0.5350821078279797 \n",
            "Epoch:  3\n",
            "392/400.0 loss: 0.5350869248689889 \n",
            "Epoch:  3\n",
            "393/400.0 loss: 0.5358793291494931 \n",
            "Epoch:  3\n",
            "394/400.0 loss: 0.5360350537149212 \n",
            "Epoch:  3\n",
            "395/400.0 loss: 0.5356881805140563 \n",
            "Epoch:  3\n",
            "396/400.0 loss: 0.5358648930749005 \n",
            "Epoch:  3\n",
            "397/400.0 loss: 0.5361812815594313 \n",
            "Epoch:  3\n",
            "398/400.0 loss: 0.5357821683088938 \n",
            "Epoch:  3\n",
            "399/400.0 loss: 0.5353647021949292 \n",
            "Epoch:  4\n",
            "0/400.0 loss: 0.30601567029953003 \n",
            "Epoch:  4\n",
            "1/400.0 loss: 0.3418385684490204 \n",
            "Epoch:  4\n",
            "2/400.0 loss: 0.382609486579895 \n",
            "Epoch:  4\n",
            "3/400.0 loss: 0.4256732165813446 \n",
            "Epoch:  4\n",
            "4/400.0 loss: 0.40867971181869506 \n",
            "Epoch:  4\n",
            "5/400.0 loss: 0.38549722731113434 \n",
            "Epoch:  4\n",
            "6/400.0 loss: 0.3934305097375597 \n",
            "Epoch:  4\n",
            "7/400.0 loss: 0.3791508637368679 \n",
            "Epoch:  4\n",
            "8/400.0 loss: 0.3804263042079078 \n",
            "Epoch:  4\n",
            "9/400.0 loss: 0.3731185793876648 \n",
            "Epoch:  4\n",
            "10/400.0 loss: 0.3887743733145974 \n",
            "Epoch:  4\n",
            "11/400.0 loss: 0.4022596875826518 \n",
            "Epoch:  4\n",
            "12/400.0 loss: 0.3895815312862396 \n",
            "Epoch:  4\n",
            "13/400.0 loss: 0.38261847623756956 \n",
            "Epoch:  4\n",
            "14/400.0 loss: 0.3745543738206228 \n",
            "Epoch:  4\n",
            "15/400.0 loss: 0.37277775816619396 \n",
            "Epoch:  4\n",
            "16/400.0 loss: 0.36809225117459016 \n",
            "Epoch:  4\n",
            "17/400.0 loss: 0.3747298899624083 \n",
            "Epoch:  4\n",
            "18/400.0 loss: 0.366913986833472 \n",
            "Epoch:  4\n",
            "19/400.0 loss: 0.36566792279481886 \n",
            "Epoch:  4\n",
            "20/400.0 loss: 0.3528913961989539 \n",
            "Epoch:  4\n",
            "21/400.0 loss: 0.356681264936924 \n",
            "Epoch:  4\n",
            "22/400.0 loss: 0.3673112126796142 \n",
            "Epoch:  4\n",
            "23/400.0 loss: 0.3883944023400545 \n",
            "Epoch:  4\n",
            "24/400.0 loss: 0.3785180050134659 \n",
            "Epoch:  4\n",
            "25/400.0 loss: 0.372053151520399 \n",
            "Epoch:  4\n",
            "26/400.0 loss: 0.3634865427458728 \n",
            "Epoch:  4\n",
            "27/400.0 loss: 0.35345532931387424 \n",
            "Epoch:  4\n",
            "28/400.0 loss: 0.3596125376121751 \n",
            "Epoch:  4\n",
            "29/400.0 loss: 0.35521556014815964 \n",
            "Epoch:  4\n",
            "30/400.0 loss: 0.34731709740815625 \n",
            "Epoch:  4\n",
            "31/400.0 loss: 0.3566369207110256 \n",
            "Epoch:  4\n",
            "32/400.0 loss: 0.36034571198803006 \n",
            "Epoch:  4\n",
            "33/400.0 loss: 0.35824087941471267 \n",
            "Epoch:  4\n",
            "34/400.0 loss: 0.35278919488191607 \n",
            "Epoch:  4\n",
            "35/400.0 loss: 0.34986005619996124 \n",
            "Epoch:  4\n",
            "36/400.0 loss: 0.34316013068766205 \n",
            "Epoch:  4\n",
            "37/400.0 loss: 0.3460079360949366 \n",
            "Epoch:  4\n",
            "38/400.0 loss: 0.3429207335679959 \n",
            "Epoch:  4\n",
            "39/400.0 loss: 0.33826996572315693 \n",
            "Epoch:  4\n",
            "40/400.0 loss: 0.3367125359250278 \n",
            "Epoch:  4\n",
            "41/400.0 loss: 0.3344534231083734 \n",
            "Epoch:  4\n",
            "42/400.0 loss: 0.3326041234094043 \n",
            "Epoch:  4\n",
            "43/400.0 loss: 0.3372175320982933 \n",
            "Epoch:  4\n",
            "44/400.0 loss: 0.3346342881520589 \n",
            "Epoch:  4\n",
            "45/400.0 loss: 0.3297194825566333 \n",
            "Epoch:  4\n",
            "46/400.0 loss: 0.32608687814245835 \n",
            "Epoch:  4\n",
            "47/400.0 loss: 0.3298960371563832 \n",
            "Epoch:  4\n",
            "48/400.0 loss: 0.33006758105998135 \n",
            "Epoch:  4\n",
            "49/400.0 loss: 0.32876398026943204 \n",
            "Epoch:  4\n",
            "50/400.0 loss: 0.3248423904764886 \n",
            "Epoch:  4\n",
            "51/400.0 loss: 0.3213347316934512 \n",
            "Epoch:  4\n",
            "52/400.0 loss: 0.3196388615189858 \n",
            "Epoch:  4\n",
            "53/400.0 loss: 0.31723309501453684 \n",
            "Epoch:  4\n",
            "54/400.0 loss: 0.3142468476837332 \n",
            "Epoch:  4\n",
            "55/400.0 loss: 0.3125628272869757 \n",
            "Epoch:  4\n",
            "56/400.0 loss: 0.311055333467952 \n",
            "Epoch:  4\n",
            "57/400.0 loss: 0.3071689012235609 \n",
            "Epoch:  4\n",
            "58/400.0 loss: 0.31344308110616975 \n",
            "Epoch:  4\n",
            "59/400.0 loss: 0.31051220099131266 \n",
            "Epoch:  4\n",
            "60/400.0 loss: 0.3111402534070562 \n",
            "Epoch:  4\n",
            "61/400.0 loss: 0.3108341107445379 \n",
            "Epoch:  4\n",
            "62/400.0 loss: 0.31362173576203606 \n",
            "Epoch:  4\n",
            "63/400.0 loss: 0.310071290936321 \n",
            "Epoch:  4\n",
            "64/400.0 loss: 0.31160004872542163 \n",
            "Epoch:  4\n",
            "65/400.0 loss: 0.31109389301502344 \n",
            "Epoch:  4\n",
            "66/400.0 loss: 0.30744194784271184 \n",
            "Epoch:  4\n",
            "67/400.0 loss: 0.3112764119663659 \n",
            "Epoch:  4\n",
            "68/400.0 loss: 0.3082832488892735 \n",
            "Epoch:  4\n",
            "69/400.0 loss: 0.31417246141604016 \n",
            "Epoch:  4\n",
            "70/400.0 loss: 0.31572815670933524 \n",
            "Epoch:  4\n",
            "71/400.0 loss: 0.31739665091865593 \n",
            "Epoch:  4\n",
            "72/400.0 loss: 0.31591028648696534 \n",
            "Epoch:  4\n",
            "73/400.0 loss: 0.31439093017094843 \n",
            "Epoch:  4\n",
            "74/400.0 loss: 0.31525178174177804 \n",
            "Epoch:  4\n",
            "75/400.0 loss: 0.31331592680592285 \n",
            "Epoch:  4\n",
            "76/400.0 loss: 0.3124647094057752 \n",
            "Epoch:  4\n",
            "77/400.0 loss: 0.3103898815237559 \n",
            "Epoch:  4\n",
            "78/400.0 loss: 0.31296169814429703 \n",
            "Epoch:  4\n",
            "79/400.0 loss: 0.3108684064820409 \n",
            "Epoch:  4\n",
            "80/400.0 loss: 0.30991986044395115 \n",
            "Epoch:  4\n",
            "81/400.0 loss: 0.308980929233679 \n",
            "Epoch:  4\n",
            "82/400.0 loss: 0.31125322325401994 \n",
            "Epoch:  4\n",
            "83/400.0 loss: 0.30854995282632963 \n",
            "Epoch:  4\n",
            "84/400.0 loss: 0.30665831320426046 \n",
            "Epoch:  4\n",
            "85/400.0 loss: 0.3085854056962701 \n",
            "Epoch:  4\n",
            "86/400.0 loss: 0.305636981223849 \n",
            "Epoch:  4\n",
            "87/400.0 loss: 0.304610031360591 \n",
            "Epoch:  4\n",
            "88/400.0 loss: 0.3069118272638723 \n",
            "Epoch:  4\n",
            "89/400.0 loss: 0.30629746197826335 \n",
            "Epoch:  4\n",
            "90/400.0 loss: 0.30601970945577045 \n",
            "Epoch:  4\n",
            "91/400.0 loss: 0.3047841369052944 \n",
            "Epoch:  4\n",
            "92/400.0 loss: 0.3075554546729852 \n",
            "Epoch:  4\n",
            "93/400.0 loss: 0.30561653425560353 \n",
            "Epoch:  4\n",
            "94/400.0 loss: 0.30706276968121526 \n",
            "Epoch:  4\n",
            "95/400.0 loss: 0.3060072141621883 \n",
            "Epoch:  4\n",
            "96/400.0 loss: 0.3061723757880865 \n",
            "Epoch:  4\n",
            "97/400.0 loss: 0.3111885670116361 \n",
            "Epoch:  4\n",
            "98/400.0 loss: 0.3177731680975418 \n",
            "Epoch:  4\n",
            "99/400.0 loss: 0.3159443837031722 \n",
            "Epoch:  4\n",
            "100/400.0 loss: 0.31873412411844376 \n",
            "Epoch:  4\n",
            "101/400.0 loss: 0.31933638040779855 \n",
            "Epoch:  4\n",
            "102/400.0 loss: 0.31918688794796907 \n",
            "Epoch:  4\n",
            "103/400.0 loss: 0.31693416429110444 \n",
            "Epoch:  4\n",
            "104/400.0 loss: 0.3167133410416898 \n",
            "Epoch:  4\n",
            "105/400.0 loss: 0.3190487111163027 \n",
            "Epoch:  4\n",
            "106/400.0 loss: 0.322734451147719 \n",
            "Epoch:  4\n",
            "107/400.0 loss: 0.32388115753592167 \n",
            "Epoch:  4\n",
            "108/400.0 loss: 0.3214640958115048 \n",
            "Epoch:  4\n",
            "109/400.0 loss: 0.32037219679491086 \n",
            "Epoch:  4\n",
            "110/400.0 loss: 0.3191053204506904 \n",
            "Epoch:  4\n",
            "111/400.0 loss: 0.317531226103061 \n",
            "Epoch:  4\n",
            "112/400.0 loss: 0.3183803752526245 \n",
            "Epoch:  4\n",
            "113/400.0 loss: 0.3160931051365639 \n",
            "Epoch:  4\n",
            "114/400.0 loss: 0.32079437624501145 \n",
            "Epoch:  4\n",
            "115/400.0 loss: 0.32015538180311176 \n",
            "Epoch:  4\n",
            "116/400.0 loss: 0.31906113630303967 \n",
            "Epoch:  4\n",
            "117/400.0 loss: 0.3209258167988668 \n",
            "Epoch:  4\n",
            "118/400.0 loss: 0.3236034193522289 \n",
            "Epoch:  4\n",
            "119/400.0 loss: 0.32434038038675983 \n",
            "Epoch:  4\n",
            "120/400.0 loss: 0.3229722660496708 \n",
            "Epoch:  4\n",
            "121/400.0 loss: 0.3251503714833592 \n",
            "Epoch:  4\n",
            "122/400.0 loss: 0.3252799621503043 \n",
            "Epoch:  4\n",
            "123/400.0 loss: 0.32470071595162153 \n",
            "Epoch:  4\n",
            "124/400.0 loss: 0.3251000637114048 \n",
            "Epoch:  4\n",
            "125/400.0 loss: 0.32406749200844576 \n",
            "Epoch:  4\n",
            "126/400.0 loss: 0.32466517133623596 \n",
            "Epoch:  4\n",
            "127/400.0 loss: 0.3229585078370292 \n",
            "Epoch:  4\n",
            "128/400.0 loss: 0.322083643500426 \n",
            "Epoch:  4\n",
            "129/400.0 loss: 0.3208732696966483 \n",
            "Epoch:  4\n",
            "130/400.0 loss: 0.32076705869941313 \n",
            "Epoch:  4\n",
            "131/400.0 loss: 0.3225923989137465 \n",
            "Epoch:  4\n",
            "132/400.0 loss: 0.32123162516189696 \n",
            "Epoch:  4\n",
            "133/400.0 loss: 0.3212716174937451 \n",
            "Epoch:  4\n",
            "134/400.0 loss: 0.3242546691110841 \n",
            "Epoch:  4\n",
            "135/400.0 loss: 0.3230917688513942 \n",
            "Epoch:  4\n",
            "136/400.0 loss: 0.32149782143261313 \n",
            "Epoch:  4\n",
            "137/400.0 loss: 0.3223853424137485 \n",
            "Epoch:  4\n",
            "138/400.0 loss: 0.3245248792143606 \n",
            "Epoch:  4\n",
            "139/400.0 loss: 0.32547961492091415 \n",
            "Epoch:  4\n",
            "140/400.0 loss: 0.32697462715895464 \n",
            "Epoch:  4\n",
            "141/400.0 loss: 0.3274226066669528 \n",
            "Epoch:  4\n",
            "142/400.0 loss: 0.32971597382134493 \n",
            "Epoch:  4\n",
            "143/400.0 loss: 0.32988396760386723 \n",
            "Epoch:  4\n",
            "144/400.0 loss: 0.32864163145422937 \n",
            "Epoch:  4\n",
            "145/400.0 loss: 0.33154458274477966 \n",
            "Epoch:  4\n",
            "146/400.0 loss: 0.3344734592654673 \n",
            "Epoch:  4\n",
            "147/400.0 loss: 0.33339763621522767 \n",
            "Epoch:  4\n",
            "148/400.0 loss: 0.33370072397109646 \n",
            "Epoch:  4\n",
            "149/400.0 loss: 0.3337104049076637 \n",
            "Epoch:  4\n",
            "150/400.0 loss: 0.3332581968842358 \n",
            "Epoch:  4\n",
            "151/400.0 loss: 0.3342471521494812 \n",
            "Epoch:  4\n",
            "152/400.0 loss: 0.3343452426294486 \n",
            "Epoch:  4\n",
            "153/400.0 loss: 0.33347656072250437 \n",
            "Epoch:  4\n",
            "154/400.0 loss: 0.3321998543075977 \n",
            "Epoch:  4\n",
            "155/400.0 loss: 0.3319346515748363 \n",
            "Epoch:  4\n",
            "156/400.0 loss: 0.3345984893192531 \n",
            "Epoch:  4\n",
            "157/400.0 loss: 0.3338640974245117 \n",
            "Epoch:  4\n",
            "158/400.0 loss: 0.3347988864114075 \n",
            "Epoch:  4\n",
            "159/400.0 loss: 0.33362901711370796 \n",
            "Epoch:  4\n",
            "160/400.0 loss: 0.33254408741497105 \n",
            "Epoch:  4\n",
            "161/400.0 loss: 0.3317024199820963 \n",
            "Epoch:  4\n",
            "162/400.0 loss: 0.3303984223744986 \n",
            "Epoch:  4\n",
            "163/400.0 loss: 0.33124703852596077 \n",
            "Epoch:  4\n",
            "164/400.0 loss: 0.33162561919201505 \n",
            "Epoch:  4\n",
            "165/400.0 loss: 0.33056627261082094 \n",
            "Epoch:  4\n",
            "166/400.0 loss: 0.3294332333712164 \n",
            "Epoch:  4\n",
            "167/400.0 loss: 0.3285578647406683 \n",
            "Epoch:  4\n",
            "168/400.0 loss: 0.32934874210220116 \n",
            "Epoch:  4\n",
            "169/400.0 loss: 0.33168307422276805 \n",
            "Epoch:  4\n",
            "170/400.0 loss: 0.3322233103041412 \n",
            "Epoch:  4\n",
            "171/400.0 loss: 0.33202821798189436 \n",
            "Epoch:  4\n",
            "172/400.0 loss: 0.3314326400572509 \n",
            "Epoch:  4\n",
            "173/400.0 loss: 0.33114117077797994 \n",
            "Epoch:  4\n",
            "174/400.0 loss: 0.33025154465011186 \n",
            "Epoch:  4\n",
            "175/400.0 loss: 0.3291566985955631 \n",
            "Epoch:  4\n",
            "176/400.0 loss: 0.33016010472750934 \n",
            "Epoch:  4\n",
            "177/400.0 loss: 0.3302245412356733 \n",
            "Epoch:  4\n",
            "178/400.0 loss: 0.3287771297774834 \n",
            "Epoch:  4\n",
            "179/400.0 loss: 0.3303823792479105 \n",
            "Epoch:  4\n",
            "180/400.0 loss: 0.3294915636147254 \n",
            "Epoch:  4\n",
            "181/400.0 loss: 0.3305938673093096 \n",
            "Epoch:  4\n",
            "182/400.0 loss: 0.3303929209261318 \n",
            "Epoch:  4\n",
            "183/400.0 loss: 0.3289762319308584 \n",
            "Epoch:  4\n",
            "184/400.0 loss: 0.3290512437957364 \n",
            "Epoch:  4\n",
            "185/400.0 loss: 0.32762630994842257 \n",
            "Epoch:  4\n",
            "186/400.0 loss: 0.3268219891357868 \n",
            "Epoch:  4\n",
            "187/400.0 loss: 0.3260125190297023 \n",
            "Epoch:  4\n",
            "188/400.0 loss: 0.3283366074282972 \n",
            "Epoch:  4\n",
            "189/400.0 loss: 0.3293196206618296 \n",
            "Epoch:  4\n",
            "190/400.0 loss: 0.33325615094204225 \n",
            "Epoch:  4\n",
            "191/400.0 loss: 0.33371242420980707 \n",
            "Epoch:  4\n",
            "192/400.0 loss: 0.3377146706023673 \n",
            "Epoch:  4\n",
            "193/400.0 loss: 0.3367680463863095 \n",
            "Epoch:  4\n",
            "194/400.0 loss: 0.337508711963892 \n",
            "Epoch:  4\n",
            "195/400.0 loss: 0.3365344315273117 \n",
            "Epoch:  4\n",
            "196/400.0 loss: 0.33799649387371117 \n",
            "Epoch:  4\n",
            "197/400.0 loss: 0.33897387242001115 \n",
            "Epoch:  4\n",
            "198/400.0 loss: 0.34004250017167936 \n",
            "Epoch:  4\n",
            "199/400.0 loss: 0.3414000429026782 \n",
            "Epoch:  4\n",
            "200/400.0 loss: 0.34104549541921164 \n",
            "Epoch:  4\n",
            "201/400.0 loss: 0.34096750629936706 \n",
            "Epoch:  4\n",
            "202/400.0 loss: 0.342412976630656 \n",
            "Epoch:  4\n",
            "203/400.0 loss: 0.3413037239738247 \n",
            "Epoch:  4\n",
            "204/400.0 loss: 0.3418956362437911 \n",
            "Epoch:  4\n",
            "205/400.0 loss: 0.3418445523321918 \n",
            "Epoch:  4\n",
            "206/400.0 loss: 0.3447698377576715 \n",
            "Epoch:  4\n",
            "207/400.0 loss: 0.3454638626247358 \n",
            "Epoch:  4\n",
            "208/400.0 loss: 0.34662859475142077 \n",
            "Epoch:  4\n",
            "209/400.0 loss: 0.3469317095442897 \n",
            "Epoch:  4\n",
            "210/400.0 loss: 0.346989543781885 \n",
            "Epoch:  4\n",
            "211/400.0 loss: 0.3460816413269572 \n",
            "Epoch:  4\n",
            "212/400.0 loss: 0.34708165351144027 \n",
            "Epoch:  4\n",
            "213/400.0 loss: 0.3472826039227091 \n",
            "Epoch:  4\n",
            "214/400.0 loss: 0.34761672628133794 \n",
            "Epoch:  4\n",
            "215/400.0 loss: 0.3488073768266649 \n",
            "Epoch:  4\n",
            "216/400.0 loss: 0.34845136385840203 \n",
            "Epoch:  4\n",
            "217/400.0 loss: 0.3505053809852502 \n",
            "Epoch:  4\n",
            "218/400.0 loss: 0.35071774852806575 \n",
            "Epoch:  4\n",
            "219/400.0 loss: 0.3512306099418889 \n",
            "Epoch:  4\n",
            "220/400.0 loss: 0.35036199123543854 \n",
            "Epoch:  4\n",
            "221/400.0 loss: 0.35043973292786257 \n",
            "Epoch:  4\n",
            "222/400.0 loss: 0.3505994700095846 \n",
            "Epoch:  4\n",
            "223/400.0 loss: 0.35108501409246984 \n",
            "Epoch:  4\n",
            "224/400.0 loss: 0.3510927475657728 \n",
            "Epoch:  4\n",
            "225/400.0 loss: 0.35062273801098354 \n",
            "Epoch:  4\n",
            "226/400.0 loss: 0.3509848126197964 \n",
            "Epoch:  4\n",
            "227/400.0 loss: 0.3515348149986382 \n",
            "Epoch:  4\n",
            "228/400.0 loss: 0.3516752601938737 \n",
            "Epoch:  4\n",
            "229/400.0 loss: 0.35169936384519807 \n",
            "Epoch:  4\n",
            "230/400.0 loss: 0.35082774675447187 \n",
            "Epoch:  4\n",
            "231/400.0 loss: 0.35102799436848225 \n",
            "Epoch:  4\n",
            "232/400.0 loss: 0.3507726082954028 \n",
            "Epoch:  4\n",
            "233/400.0 loss: 0.35097720459676707 \n",
            "Epoch:  4\n",
            "234/400.0 loss: 0.3519692535571595 \n",
            "Epoch:  4\n",
            "235/400.0 loss: 0.35113395666861436 \n",
            "Epoch:  4\n",
            "236/400.0 loss: 0.3520856644753917 \n",
            "Epoch:  4\n",
            "237/400.0 loss: 0.35236872812466963 \n",
            "Epoch:  4\n",
            "238/400.0 loss: 0.35298979873126024 \n",
            "Epoch:  4\n",
            "239/400.0 loss: 0.35196265135891736 \n",
            "Epoch:  4\n",
            "240/400.0 loss: 0.35259876982985194 \n",
            "Epoch:  4\n",
            "241/400.0 loss: 0.35341695128085693 \n",
            "Epoch:  4\n",
            "242/400.0 loss: 0.3531060319838455 \n",
            "Epoch:  4\n",
            "243/400.0 loss: 0.3543766009483914 \n",
            "Epoch:  4\n",
            "244/400.0 loss: 0.35413516229208636 \n",
            "Epoch:  4\n",
            "245/400.0 loss: 0.3537441848709089 \n",
            "Epoch:  4\n",
            "246/400.0 loss: 0.3542316871344561 \n",
            "Epoch:  4\n",
            "247/400.0 loss: 0.3534676189113769 \n",
            "Epoch:  4\n",
            "248/400.0 loss: 0.3525867226223151 \n",
            "Epoch:  4\n",
            "249/400.0 loss: 0.35391888152062895 \n",
            "Epoch:  4\n",
            "250/400.0 loss: 0.3528022193962122 \n",
            "Epoch:  4\n",
            "251/400.0 loss: 0.35211676526223384 \n",
            "Epoch:  4\n",
            "252/400.0 loss: 0.3525050142448646 \n",
            "Epoch:  4\n",
            "253/400.0 loss: 0.3518106343855304 \n",
            "Epoch:  4\n",
            "254/400.0 loss: 0.35149631338084447 \n",
            "Epoch:  4\n",
            "255/400.0 loss: 0.3506359962775605 \n",
            "Epoch:  4\n",
            "256/400.0 loss: 0.35037123062557285 \n",
            "Epoch:  4\n",
            "257/400.0 loss: 0.3503058409072863 \n",
            "Epoch:  4\n",
            "258/400.0 loss: 0.3492381091312322 \n",
            "Epoch:  4\n",
            "259/400.0 loss: 0.3497193856451374 \n",
            "Epoch:  4\n",
            "260/400.0 loss: 0.3487521672756964 \n",
            "Epoch:  4\n",
            "261/400.0 loss: 0.3489786088608831 \n",
            "Epoch:  4\n",
            "262/400.0 loss: 0.34806889472635527 \n",
            "Epoch:  4\n",
            "263/400.0 loss: 0.3476782779378647 \n",
            "Epoch:  4\n",
            "264/400.0 loss: 0.3478911450027295 \n",
            "Epoch:  4\n",
            "265/400.0 loss: 0.34857353597487273 \n",
            "Epoch:  4\n",
            "266/400.0 loss: 0.3495410489483496 \n",
            "Epoch:  4\n",
            "267/400.0 loss: 0.34975327069023204 \n",
            "Epoch:  4\n",
            "268/400.0 loss: 0.35201587626315844 \n",
            "Epoch:  4\n",
            "269/400.0 loss: 0.3521202737120567 \n",
            "Epoch:  4\n",
            "270/400.0 loss: 0.35203709050573107 \n",
            "Epoch:  4\n",
            "271/400.0 loss: 0.351965373779154 \n",
            "Epoch:  4\n",
            "272/400.0 loss: 0.3526476838458807 \n",
            "Epoch:  4\n",
            "273/400.0 loss: 0.3537918936841897 \n",
            "Epoch:  4\n",
            "274/400.0 loss: 0.3543405193225904 \n",
            "Epoch:  4\n",
            "275/400.0 loss: 0.35631941805553174 \n",
            "Epoch:  4\n",
            "276/400.0 loss: 0.3573130128858107 \n",
            "Epoch:  4\n",
            "277/400.0 loss: 0.35806223413766286 \n",
            "Epoch:  4\n",
            "278/400.0 loss: 0.359404817770993 \n",
            "Epoch:  4\n",
            "279/400.0 loss: 0.3586764661994364 \n",
            "Epoch:  4\n",
            "280/400.0 loss: 0.35907052490475766 \n",
            "Epoch:  4\n",
            "281/400.0 loss: 0.358559939838576 \n",
            "Epoch:  4\n",
            "282/400.0 loss: 0.35845857570375655 \n",
            "Epoch:  4\n",
            "283/400.0 loss: 0.3577989348354684 \n",
            "Epoch:  4\n",
            "284/400.0 loss: 0.3575794067429869 \n",
            "Epoch:  4\n",
            "285/400.0 loss: 0.35743531085863395 \n",
            "Epoch:  4\n",
            "286/400.0 loss: 0.357860617949676 \n",
            "Epoch:  4\n",
            "287/400.0 loss: 0.35896692840227235 \n",
            "Epoch:  4\n",
            "288/400.0 loss: 0.35923312600560253 \n",
            "Epoch:  4\n",
            "289/400.0 loss: 0.35889195112575745 \n",
            "Epoch:  4\n",
            "290/400.0 loss: 0.3594043964705721 \n",
            "Epoch:  4\n",
            "291/400.0 loss: 0.3601859933632898 \n",
            "Epoch:  4\n",
            "292/400.0 loss: 0.3595394603145204 \n",
            "Epoch:  4\n",
            "293/400.0 loss: 0.359628949352369 \n",
            "Epoch:  4\n",
            "294/400.0 loss: 0.3598579250276089 \n",
            "Epoch:  4\n",
            "295/400.0 loss: 0.3594751016840943 \n",
            "Epoch:  4\n",
            "296/400.0 loss: 0.3604405302717429 \n",
            "Epoch:  4\n",
            "297/400.0 loss: 0.3617928251249078 \n",
            "Epoch:  4\n",
            "298/400.0 loss: 0.36253612567000965 \n",
            "Epoch:  4\n",
            "299/400.0 loss: 0.3620180521532893 \n",
            "Epoch:  4\n",
            "300/400.0 loss: 0.3634996218266479 \n",
            "Epoch:  4\n",
            "301/400.0 loss: 0.3630233871941732 \n",
            "Epoch:  4\n",
            "302/400.0 loss: 0.3638133533643221 \n",
            "Epoch:  4\n",
            "303/400.0 loss: 0.36364185438785507 \n",
            "Epoch:  4\n",
            "304/400.0 loss: 0.3637408266424156 \n",
            "Epoch:  4\n",
            "305/400.0 loss: 0.3629929128352528 \n",
            "Epoch:  4\n",
            "306/400.0 loss: 0.36259575034051844 \n",
            "Epoch:  4\n",
            "307/400.0 loss: 0.36281368432735855 \n",
            "Epoch:  4\n",
            "308/400.0 loss: 0.36367548386111226 \n",
            "Epoch:  4\n",
            "309/400.0 loss: 0.3635890720952903 \n",
            "Epoch:  4\n",
            "310/400.0 loss: 0.3630484964135567 \n",
            "Epoch:  4\n",
            "311/400.0 loss: 0.36293880303557485 \n",
            "Epoch:  4\n",
            "312/400.0 loss: 0.3624126359510917 \n",
            "Epoch:  4\n",
            "313/400.0 loss: 0.3623439449057647 \n",
            "Epoch:  4\n",
            "314/400.0 loss: 0.3614765733125664 \n",
            "Epoch:  4\n",
            "315/400.0 loss: 0.36067913589362477 \n",
            "Epoch:  4\n",
            "316/400.0 loss: 0.3600150555818803 \n",
            "Epoch:  4\n",
            "317/400.0 loss: 0.3601805850184001 \n",
            "Epoch:  4\n",
            "318/400.0 loss: 0.3594899390908805 \n",
            "Epoch:  4\n",
            "319/400.0 loss: 0.3593155660084449 \n",
            "Epoch:  4\n",
            "320/400.0 loss: 0.3585901669229488 \n",
            "Epoch:  4\n",
            "321/400.0 loss: 0.35775938057427453 \n",
            "Epoch:  4\n",
            "322/400.0 loss: 0.3595124785860441 \n",
            "Epoch:  4\n",
            "323/400.0 loss: 0.3590901593942149 \n",
            "Epoch:  4\n",
            "324/400.0 loss: 0.3586053043718521 \n",
            "Epoch:  4\n",
            "325/400.0 loss: 0.35840214346678345 \n",
            "Epoch:  4\n",
            "326/400.0 loss: 0.3580415285895906 \n",
            "Epoch:  4\n",
            "327/400.0 loss: 0.3583811798314678 \n",
            "Epoch:  4\n",
            "328/400.0 loss: 0.35814742681692074 \n",
            "Epoch:  4\n",
            "329/400.0 loss: 0.3587298283635667 \n",
            "Epoch:  4\n",
            "330/400.0 loss: 0.3592440338855964 \n",
            "Epoch:  4\n",
            "331/400.0 loss: 0.35876813626298343 \n",
            "Epoch:  4\n",
            "332/400.0 loss: 0.35876168401257413 \n",
            "Epoch:  4\n",
            "333/400.0 loss: 0.3592557966552987 \n",
            "Epoch:  4\n",
            "334/400.0 loss: 0.3604853621725716 \n",
            "Epoch:  4\n",
            "335/400.0 loss: 0.3624468228136677 \n",
            "Epoch:  4\n",
            "336/400.0 loss: 0.36169077897062996 \n",
            "Epoch:  4\n",
            "337/400.0 loss: 0.3612150719510557 \n",
            "Epoch:  4\n",
            "338/400.0 loss: 0.36056983803885173 \n",
            "Epoch:  4\n",
            "339/400.0 loss: 0.3600895112818655 \n",
            "Epoch:  4\n",
            "340/400.0 loss: 0.36004266211670166 \n",
            "Epoch:  4\n",
            "341/400.0 loss: 0.3597730081746278 \n",
            "Epoch:  4\n",
            "342/400.0 loss: 0.36078824775168566 \n",
            "Epoch:  4\n",
            "343/400.0 loss: 0.3615096948586058 \n",
            "Epoch:  4\n",
            "344/400.0 loss: 0.361984090604212 \n",
            "Epoch:  4\n",
            "345/400.0 loss: 0.36155867739176817 \n",
            "Epoch:  4\n",
            "346/400.0 loss: 0.36104993044428246 \n",
            "Epoch:  4\n",
            "347/400.0 loss: 0.36145371326041975 \n",
            "Epoch:  4\n",
            "348/400.0 loss: 0.3609828572709615 \n",
            "Epoch:  4\n",
            "349/400.0 loss: 0.36044079851891314 \n",
            "Epoch:  4\n",
            "350/400.0 loss: 0.3612465816324423 \n",
            "Epoch:  4\n",
            "351/400.0 loss: 0.36155969195533544 \n",
            "Epoch:  4\n",
            "352/400.0 loss: 0.36078238579056754 \n",
            "Epoch:  4\n",
            "353/400.0 loss: 0.36049275309647205 \n",
            "Epoch:  4\n",
            "354/400.0 loss: 0.35993000582700047 \n",
            "Epoch:  4\n",
            "355/400.0 loss: 0.3602446550712659 \n",
            "Epoch:  4\n",
            "356/400.0 loss: 0.3601302449755809 \n",
            "Epoch:  4\n",
            "357/400.0 loss: 0.3595807640891335 \n",
            "Epoch:  4\n",
            "358/400.0 loss: 0.359951708507322 \n",
            "Epoch:  4\n",
            "359/400.0 loss: 0.3597565944306552 \n",
            "Epoch:  4\n",
            "360/400.0 loss: 0.3602281977574746 \n",
            "Epoch:  4\n",
            "361/400.0 loss: 0.3597240691582636 \n",
            "Epoch:  4\n",
            "362/400.0 loss: 0.36021407066585276 \n",
            "Epoch:  4\n",
            "363/400.0 loss: 0.3597750934659616 \n",
            "Epoch:  4\n",
            "364/400.0 loss: 0.36083335279397766 \n",
            "Epoch:  4\n",
            "365/400.0 loss: 0.36075546856094254 \n",
            "Epoch:  4\n",
            "366/400.0 loss: 0.3600625759269788 \n",
            "Epoch:  4\n",
            "367/400.0 loss: 0.36167196424313536 \n",
            "Epoch:  4\n",
            "368/400.0 loss: 0.3621407958570373 \n",
            "Epoch:  4\n",
            "369/400.0 loss: 0.3620238364246246 \n",
            "Epoch:  4\n",
            "370/400.0 loss: 0.36141031527655787 \n",
            "Epoch:  4\n",
            "371/400.0 loss: 0.36165956677167965 \n",
            "Epoch:  4\n",
            "372/400.0 loss: 0.3622502093840061 \n",
            "Epoch:  4\n",
            "373/400.0 loss: 0.3616761711929093 \n",
            "Epoch:  4\n",
            "374/400.0 loss: 0.36237692229946455 \n",
            "Epoch:  4\n",
            "375/400.0 loss: 0.36260093202655935 \n",
            "Epoch:  4\n",
            "376/400.0 loss: 0.3625546030660681 \n",
            "Epoch:  4\n",
            "377/400.0 loss: 0.3622375550980448 \n",
            "Epoch:  4\n",
            "378/400.0 loss: 0.3624474720090706 \n",
            "Epoch:  4\n",
            "379/400.0 loss: 0.36177713893550006 \n",
            "Epoch:  4\n",
            "380/400.0 loss: 0.36202902359560407 \n",
            "Epoch:  4\n",
            "381/400.0 loss: 0.3619454640270996 \n",
            "Epoch:  4\n",
            "382/400.0 loss: 0.36175409137385633 \n",
            "Epoch:  4\n",
            "383/400.0 loss: 0.3620066264702473 \n",
            "Epoch:  4\n",
            "384/400.0 loss: 0.3615697160072915 \n",
            "Epoch:  4\n",
            "385/400.0 loss: 0.3614175250859921 \n",
            "Epoch:  4\n",
            "386/400.0 loss: 0.36288342510352456 \n",
            "Epoch:  4\n",
            "387/400.0 loss: 0.3627433059353036 \n",
            "Epoch:  4\n",
            "388/400.0 loss: 0.3629219116676589 \n",
            "Epoch:  4\n",
            "389/400.0 loss: 0.3629346388941392 \n",
            "Epoch:  4\n",
            "390/400.0 loss: 0.3638744044696431 \n",
            "Epoch:  4\n",
            "391/400.0 loss: 0.3640100072442117 \n",
            "Epoch:  4\n",
            "392/400.0 loss: 0.3637774467525136 \n",
            "Epoch:  4\n",
            "393/400.0 loss: 0.36386290849730146 \n",
            "Epoch:  4\n",
            "394/400.0 loss: 0.3646113743416116 \n",
            "Epoch:  4\n",
            "395/400.0 loss: 0.366084724881056 \n",
            "Epoch:  4\n",
            "396/400.0 loss: 0.366154179605714 \n",
            "Epoch:  4\n",
            "397/400.0 loss: 0.36551742179871505 \n",
            "Epoch:  4\n",
            "398/400.0 loss: 0.36555614446600276 \n",
            "Epoch:  4\n",
            "399/400.0 loss: 0.366635982086882 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZffdI9Wn-dT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5166b82-7786-4c23-d978-4899f49f0513"
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        loss = loss_func(logits, labels)\n",
        "        numpy_logits = logits.cpu().detach().numpy()\n",
        "        \n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "        all_logits += list(numpy_logits[:, 0])\n",
        "        \n",
        "print(classification_report(test_y, bert_predicted))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.63      0.76      0.69       429\n",
            "        True       0.63      0.47      0.54       371\n",
            "\n",
            "    accuracy                           0.63       800\n",
            "   macro avg       0.63      0.62      0.62       800\n",
            "weighted avg       0.63      0.63      0.62       800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaBqUbVAIeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92b2ad6-5f68-48a8-bce4-dd6e9201381a"
      },
      "source": [
        "print(test_y)\n",
        "print(bert_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True False False  True  True False False  True  True  True False False\n",
            "  True False False  True False  True False  True False False  True False\n",
            " False  True  True  True False False False  True False False False False\n",
            "  True  True False False  True False  True  True False False False False\n",
            "  True  True False  True  True  True  True False False False  True  True\n",
            " False  True  True False  True False  True False False False  True False\n",
            "  True  True  True False False  True False  True False False  True False\n",
            "  True False False  True False  True False False False False  True False\n",
            " False False False False  True  True False  True  True False  True False\n",
            "  True  True  True False False False False  True  True False False False\n",
            "  True False False False  True False False False  True  True False  True\n",
            " False  True  True False  True False  True  True False  True  True False\n",
            " False False False  True False False  True False False False False  True\n",
            "  True False  True False  True  True False False  True False  True False\n",
            " False False False  True False  True False False False False False False\n",
            "  True False False  True False  True  True  True False  True False False\n",
            " False  True False  True False  True  True False False  True False  True\n",
            " False  True False  True  True  True False  True False False  True  True\n",
            " False False False  True  True  True False  True  True False False False\n",
            "  True  True False False  True False False  True  True False False False\n",
            "  True  True False False  True  True  True  True  True False  True  True\n",
            " False  True  True  True  True False  True False False False  True False\n",
            "  True False  True False  True False False  True False False False False\n",
            "  True  True False False  True  True False False False False False False\n",
            " False False False  True False False False  True False  True  True  True\n",
            " False False  True  True  True  True  True  True  True  True False  True\n",
            "  True False  True False  True  True  True False  True  True  True  True\n",
            " False False False False False False False False False  True  True False\n",
            "  True False  True  True  True False False  True False False False  True\n",
            "  True False False  True False False False False  True False False False\n",
            "  True  True  True False  True False  True False  True  True  True False\n",
            " False  True False False  True False False False False False  True  True\n",
            "  True  True  True False False False False  True  True  True False  True\n",
            "  True  True  True  True  True  True  True False  True False  True  True\n",
            "  True  True False  True  True  True  True  True False  True  True  True\n",
            " False  True False  True False False False  True  True False  True False\n",
            "  True False  True  True  True  True False False  True False  True  True\n",
            " False False False  True False False False  True  True  True  True False\n",
            " False  True  True False  True  True  True False  True  True  True False\n",
            " False False False False  True False  True  True  True False False  True\n",
            " False  True False False  True False False False False  True False  True\n",
            " False False  True False False  True  True  True False False False  True\n",
            "  True False False  True False False  True  True  True False False False\n",
            "  True False False False False False  True  True  True  True False False\n",
            " False False  True  True  True False False  True False  True False False\n",
            "  True False False False  True False  True False  True  True False  True\n",
            " False False  True False  True  True  True False  True False  True  True\n",
            " False  True  True  True False False  True  True False  True False False\n",
            "  True False  True False False False False False False False False False\n",
            " False False False  True False False False  True  True False False  True\n",
            " False False False  True  True  True  True  True False  True  True False\n",
            " False False False False False False False False  True False  True  True\n",
            " False False  True False  True False  True False  True False  True  True\n",
            "  True False False False  True  True False False  True  True  True False\n",
            " False False  True False False  True False  True  True False  True False\n",
            "  True  True False  True False False False False False False False  True\n",
            " False  True False False False False  True  True  True False  True  True\n",
            " False False  True False False False False False  True  True False  True\n",
            "  True  True False  True False False False False  True  True  True  True\n",
            " False False  True False False False  True  True  True  True False  True\n",
            "  True False  True  True False  True False False  True False  True False\n",
            "  True  True False False False  True  True False  True  True False  True\n",
            " False False  True  True  True False  True False False False  True False\n",
            " False False  True False False False  True False False False  True  True\n",
            " False  True  True  True False False False  True False False  True False\n",
            "  True  True False False False  True  True False False False  True False\n",
            "  True  True  True False False False  True False]\n",
            "[False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, True, False, True, False, False, True, True, False, False, True, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, True, False, True, False, True, False, False, False, False, False, True, False, False, True, True, True, True, False, True, True, False, False, False, False, True, True, False, False, True, False, True, False, False, False, False, False, True, False, True, True, False, False, False, False, False, True, False, False, False, False, True, True, True, False, False, True, False, False, False, True, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, True, False, False, False, False, True, False, False, True, False, True, False, False, False, False, False, True, False, False, False, True, True, False, True, False, False, True, True, True, False, False, False, False, False, False, False, False, True, False, False, True, False, False, True, False, False, True, False, False, False, False, False, True, False, False, False, True, False, False, False, False, True, False, True, False, False, True, False, False, False, False, False, False, True, False, True, False, False, False, False, True, True, False, True, False, False, False, True, False, False, False, True, True, True, False, False, True, False, True, False, False, True, False, False, False, False, True, True, False, False, False, True, True, True, False, True, True, True, False, True, True, True, False, True, False, True, True, True, True, False, False, False, True, True, False, False, True, False, False, False, False, True, True, False, False, False, True, False, False, False, True, False, False, True, False, True, True, False, False, False, False, False, False, False, True, True, False, False, False, False, True, True, False, False, True, True, False, False, True, False, True, False, True, True, False, False, True, False, True, True, False, True, False, False, False, True, False, False, False, False, False, False, True, False, True, True, False, False, False, True, True, False, False, False, False, False, True, False, False, False, False, False, False, True, False, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False, True, True, False, False, True, False, True, True, True, False, True, False, True, True, True, True, False, False, False, True, False, True, True, False, True, True, True, False, False, True, True, True, False, True, False, False, True, False, False, False, True, True, False, False, False, True, False, False, True, False, False, False, False, False, True, False, False, True, True, False, False, False, False, False, True, False, True, True, True, False, True, False, False, True, True, False, False, True, False, False, False, False, True, True, False, False, True, True, False, True, False, False, False, False, False, True, False, True, False, False, False, True, True, True, False, True, False, False, False, True, True, False, False, True, False, True, False, False, False, True, True, False, False, False, False, True, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, True, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, True, False, False, False, False, True, False, True, False, False, False, False, False, False, True, False, True, False, False, False, False, True, True, True, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, True, True, True, False, False, True, True, False, False, False, True, True, False, False, False, True, False, False, False, False, True, True, True, False, False, False, True, False, True, True, True, False, True, False, True, True, True, False, True, False, False, False, True, True, False, False, False, True, True, False, False, True, False, False, False, False, True, True, False, True, False, False, False, True, False, False, False, True, False, False, True, True, True, False, False, True, False, True, True, True, False, False, False, True, True, True, False, True, True, False, False, False, False, False, False, True, False, False, False, True, False, True, True, False, False, False, False, False, False, False, True, True, True, False, False, False, True, True, True, False, True, False, True, False, False, True, True, False, False, False, False, False, False, False, True, False, True, True, True, False, True, True, False, True, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, True, True, True, False, False, True, False, False, True, True, False, False, True, True, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}