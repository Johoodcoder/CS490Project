{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS490Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRUoJsu76EvmSOrAB6qQO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johoodcoder/CS490Project/blob/hood/Notebooks/CS490ProjectHuggingImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTZbJ1SJ53XO"
      },
      "source": [
        "Non-preinstalled module installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm5_ujD458U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6b3585-c7d3-4d14-8645-46be65805d14"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWz664Rd6MeU"
      },
      "source": [
        "Import all the stuff we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbufH4ZX8X5N"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CONST_BATCH_SIZE = 10\n",
        "CONST_MAX_SEQ_LENGTH = 128\n",
        "CONST_NUM_EPOCHS = 4\n",
        "CONST_LEARN_RATE = 2e-5\n",
        "CONST_EPSILON = 1e-8"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2AUQtRf6SiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3196e6-c585-475f-f106-f7178ea1e42e"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9SFswG6GWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31b8e4a-4669-4c3c-abf8-533e6091298b"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUA3aAGM7G7u"
      },
      "source": [
        "Load our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a-5pyC08dzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1aface-2f7b-4555-d76c-aa295bade1b5"
      },
      "source": [
        "# Load dataset\n",
        "# df = pd.read_csv(\"condensed_fake_real_news_SANITIZED.csv\")\n",
        "df = pd.read_csv(\"LIARPLUSTrainSanitized.csv\")\n",
        "df = df[['text', 'type']]\n",
        "print('Total number of data entries: {:,}\\n'.format(df.shape[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of data entries: 10,234\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHnQVRq8z0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "384e3c65-4e3f-4234-ad07-6b84bdaa5123"
      },
      "source": [
        "df = df[df['type'].isin(['fake', 'real'])]\n",
        "# Scramble data indexes from dataset. Random_state is a seed. This is producing random scrambles for some reason even with the same random_state seed.\n",
        "df = df.dropna()\n",
        "df = df.sample(frac=1, random_state = 23).reset_index(drop=True)\n",
        "df.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>Clinton took Trump to task for saying that the...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7471</th>\n",
              "      <td>Hagan told a reporter he had read reports that...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9583</th>\n",
              "      <td>ABORs mailer says Daugherty is endorsed by the...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2366</th>\n",
              "      <td>Bruun also said he wholly supports NOAA coming...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3284</th>\n",
              "      <td>But clearly some change is coming. It's not re...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>It is not \"fair to say the science is in dispu...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5199</th>\n",
              "      <td>It lost 1,125 more when companies closed opera...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4652</th>\n",
              "      <td>Romney has a point that the current recovery i...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>Stirewalt said that under penalty of perjury, ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6690</th>\n",
              "      <td>Trump said, \"I was totally against the war in ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  type\n",
              "683   Clinton took Trump to task for saying that the...  fake\n",
              "7471  Hagan told a reporter he had read reports that...  fake\n",
              "9583  ABORs mailer says Daugherty is endorsed by the...  real\n",
              "2366  Bruun also said he wholly supports NOAA coming...  real\n",
              "3284  But clearly some change is coming. It's not re...  real\n",
              "1095  It is not \"fair to say the science is in dispu...  real\n",
              "5199  It lost 1,125 more when companies closed opera...  real\n",
              "4652  Romney has a point that the current recovery i...  real\n",
              "469   Stirewalt said that under penalty of perjury, ...  fake\n",
              "6690  Trump said, \"I was totally against the war in ...  real"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSluqzG8-lh"
      },
      "source": [
        "Seperate training and testing subsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wOwpOde8_WC"
      },
      "source": [
        "train_data_df = df.head(1000)\n",
        "test_data_df = df.tail(200)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_VsapAk87Kk"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "train_texts = train_data_df.text.values\n",
        "train_labels = train_data_df.type.values\n",
        "\n",
        "test_texts = test_data_df.text.values\n",
        "test_labels = test_data_df.type.values\n",
        "\n",
        "# If value == fake then make it 1. Else 0. Funky workaround as bert expects longs\n",
        "train_labels = np.array(train_labels == 'fake')\n",
        "train_labels = np.multiply(train_labels,1)\n",
        "test_labels = np.array(test_labels) == 'fake'\n",
        "test_labels = np.multiply(test_labels,1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86XhtxYQ94QM"
      },
      "source": [
        "Load and test tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQi8q3Fs9tqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cba797-c8d9-4411-ddb5-e017d714f8d1"
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', train_texts[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(train_texts[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_texts[0])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            " Original:  Bike Austin said: \"Bike lanes and sidewalks have been proven to reduce crashes by up to 38 percent on Austins streets. \"Research suggests big drops in pedestrian-vehicle accidents when sidewalks are introduced. But Bike Austin didnt offer nor did we find research showing the addition of bike lanes in themselves or bike lanes plus sidewalks resulted in anypercentage plummet in crashes. Instead, the city analysisstates that reconfiguring lanes on part of one road, which also gainedbike lanes, preceded 38 percent fewercrashes--with crashreductions averaging 29 percent among five road-diet projects.\n",
            "Tokenized:  ['bike', 'austin', 'said', ':', '\"', 'bike', 'lanes', 'and', 'sidewalks', 'have', 'been', 'proven', 'to', 'reduce', 'crashes', 'by', 'up', 'to', '38', 'percent', 'on', 'austin', '##s', 'streets', '.', '\"', 'research', 'suggests', 'big', 'drops', 'in', 'pedestrian', '-', 'vehicle', 'accidents', 'when', 'sidewalks', 'are', 'introduced', '.', 'but', 'bike', 'austin', 'didn', '##t', 'offer', 'nor', 'did', 'we', 'find', 'research', 'showing', 'the', 'addition', 'of', 'bike', 'lanes', 'in', 'themselves', 'or', 'bike', 'lanes', 'plus', 'sidewalks', 'resulted', 'in', 'any', '##per', '##cent', '##age', 'plum', '##met', 'in', 'crashes', '.', 'instead', ',', 'the', 'city', 'analysis', '##sta', '##tes', 'that', 'rec', '##on', '##fi', '##gur', '##ing', 'lanes', 'on', 'part', 'of', 'one', 'road', ',', 'which', 'also', 'gained', '##bi', '##ke', 'lanes', ',', 'preceded', '38', 'percent', 'fewer', '##cr', '##ash', '##es', '-', '-', 'with', 'crash', '##red', '##uc', '##tions', 'averaging', '29', 'percent', 'among', 'five', 'road', '-', 'diet', 'projects', '.']\n",
            "Token IDs:  [7997, 5899, 2056, 1024, 1000, 7997, 10914, 1998, 28386, 2031, 2042, 10003, 2000, 5547, 19119, 2011, 2039, 2000, 4229, 3867, 2006, 5899, 2015, 4534, 1012, 1000, 2470, 6083, 2502, 9010, 1999, 14662, 1011, 4316, 13436, 2043, 28386, 2024, 3107, 1012, 2021, 7997, 5899, 2134, 2102, 3749, 4496, 2106, 2057, 2424, 2470, 4760, 1996, 2804, 1997, 7997, 10914, 1999, 3209, 2030, 7997, 10914, 4606, 28386, 4504, 1999, 2151, 4842, 13013, 4270, 22088, 11368, 1999, 19119, 1012, 2612, 1010, 1996, 2103, 4106, 9153, 4570, 2008, 28667, 2239, 8873, 27390, 2075, 10914, 2006, 2112, 1997, 2028, 2346, 1010, 2029, 2036, 4227, 5638, 3489, 10914, 1010, 11677, 4229, 3867, 8491, 26775, 11823, 2229, 1011, 1011, 2007, 5823, 5596, 14194, 9285, 14985, 2756, 3867, 2426, 2274, 2346, 1011, 8738, 3934, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIuVMsx-NJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc47c62b-7cb9-4d5a-cee3-0292bc584f6e"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every news text...\n",
        "for text in train_texts:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum text length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max text length: ', max_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max text length:  310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPRn2Sta-k1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f4cfb2-db06-4eca-9c1b-e2e8f76afed5"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training entries: {:,}\\n'.format(train_data_df.shape[0]))\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for text in train_texts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = CONST_MAX_SEQ_LENGTH,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train_labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of training entries: 1,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Bike Austin said: \"Bike lanes and sidewalks have been proven to reduce crashes by up to 38 percent on Austins streets. \"Research suggests big drops in pedestrian-vehicle accidents when sidewalks are introduced. But Bike Austin didnt offer nor did we find research showing the addition of bike lanes in themselves or bike lanes plus sidewalks resulted in anypercentage plummet in crashes. Instead, the city analysisstates that reconfiguring lanes on part of one road, which also gainedbike lanes, preceded 38 percent fewercrashes--with crashreductions averaging 29 percent among five road-diet projects.\n",
            "Token IDs: tensor([  101,  7997,  5899,  2056,  1024,  1000,  7997, 10914,  1998, 28386,\n",
            "         2031,  2042, 10003,  2000,  5547, 19119,  2011,  2039,  2000,  4229,\n",
            "         3867,  2006,  5899,  2015,  4534,  1012,  1000,  2470,  6083,  2502,\n",
            "         9010,  1999, 14662,  1011,  4316, 13436,  2043, 28386,  2024,  3107,\n",
            "         1012,  2021,  7997,  5899,  2134,  2102,  3749,  4496,  2106,  2057,\n",
            "         2424,  2470,  4760,  1996,  2804,  1997,  7997, 10914,  1999,  3209,\n",
            "         2030,  7997, 10914,  4606, 28386,  4504,  1999,  2151,  4842, 13013,\n",
            "         4270, 22088, 11368,  1999, 19119,  1012,  2612,  1010,  1996,  2103,\n",
            "         4106,  9153,  4570,  2008, 28667,  2239,  8873, 27390,  2075, 10914,\n",
            "         2006,  2112,  1997,  2028,  2346,  1010,  2029,  2036,  4227,  5638,\n",
            "         3489, 10914,  1010, 11677,  4229,  3867,  8491, 26775, 11823,  2229,\n",
            "         1011,  1011,  2007,  5823,  5596, 14194,  9285, 14985,  2756,  3867,\n",
            "         2426,  2274,  2346,  1011,  8738,  3934,  1012,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbspJd0B_zWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7736c676-fe7a-4a27-cc04-11b49a5a7ac4"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  900 training samples\n",
            "  100 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0x6YgtAFm8"
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = CONST_BATCH_SIZE\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZRYYD-5AOdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b8acd5-587c-4e79-dfb3-e058a4910941"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iznqE09hAXat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f7f856-3205-444f-b120-40f465d09371"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3lXGKtmAckv"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = CONST_LEARN_RATE, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = CONST_EPSILON # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5QfRjwoAkMc"
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = CONST_NUM_EPOCHS\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWtGyTIKAt-B"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58So89vWA7wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e3c37d-b5eb-4287-e22d-348f3d63e332"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 10 batches.\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epoch took: 0:00:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
            "  Batch    80  of     90.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:08 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "of5AwpaONAph",
        "outputId": "2af18cf1-ec5d-4a64-df42-636e39c8d686"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0:00:46</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.62         0.60           0.72       0:00:46         0:00:02\n",
              "2               0.60         0.58           0.73       0:00:45         0:00:02\n",
              "3               0.51         0.59           0.68       0:00:45         0:00:02\n",
              "4               0.38         0.65           0.69       0:00:45         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drU08e--BJEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "e4c0a675-4efb-4920-ef3c-41d18392e329"
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f8da160ad10>,\n",
              "  <matplotlib.axis.XTick at 0x7f8da160acd0>,\n",
              "  <matplotlib.axis.XTick at 0x7f8da160a910>,\n",
              "  <matplotlib.axis.XTick at 0x7f8da158be90>],\n",
              " <a list of 4 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsQGHV-6NTrg",
        "outputId": "c1c476ed-0a1f-4c62-81c5-e9565e38fe64"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of test entries: {:,}\\n'.format(test_data_df.shape[0]))\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for text in test_texts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = CONST_MAX_SEQ_LENGTH,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = CONST_BATCH_SIZE  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test entries: 200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LarLkCN1Qh5E",
        "outputId": "5e4deefc-4502-47b9-a882-f3782c232fe9"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 200 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3El4O9kASTtX",
        "outputId": "1225db56-f44c-4c6f-e225-312b7f43a491"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (test_labels.sum(), len(test_labels), (test_labels.sum() / len(test_labels) * 100.0)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 59 of 200 (29.50%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAtj6RjqThiP",
        "outputId": "1e600702-df62-4ab6-a83f-c7ac8abf89d4"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "QP1PY1UFVwIT",
        "outputId": "396b10a1-2c12-4306-b015-f062defbc9cb"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrXvz8jhWANB",
        "outputId": "f4acbc9a-be04-4037-8a06-a86151247419"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: -0.023\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}